\chapter{Algoritmien suunnittelu}

Kuinka voi suunnitella hyvän algoritmin?
On selvää, ettei tähän kysymykseen ole yhtä helppoa vastausta.
Yhtä hyvin voisi kysyä, kuinka voi kirjoittaa hyvän kirjan
tai säveltää hyvää musiikkia.
Algoritmien suunnittelu on taito, jonka oppiminen vie aikaa.

Hyvä tavoite algoritmien suunnittelussa on saada aikaan
algoritmi, joka toimii ajassa $O(n)$ tai $O(n \log n)$.
Tällaisen algoritmin etuna on, että se toimii tehokkaasti
myös silloin, kun syötteen koko $n$ on suuri.
Tavoitteen asettaminen etukäteen on hyödyllistä,
koska kun tiedämme tavoitteen, voimme ottaa sen suunnittelumme
lähtökohdaksi ja rajata sen avulla mahdollisia
lähestymistapoja, joita voimme käyttää.

\section{Algoritmin tehostaminen}

Millainen on algoritmi, joka vie aikaa $O(n)$ tai $O(n \log n)$?
Tämä tarkoittaa,
että kun algoritmille annetaan syötteenä $n$ alkiota,
se saa käyttää jokaisen alkion käsittelyyn
vain pienen määrän aikaa.
Niinpä algoritmissa tulisi esiintyä seuraavan kaltaisia silmukoita:

\begin{code}
for i = 0 to n-1
    // tee jotain nopeaa
\end{code}

Tässä ''jotain nopeaa'' tarkoittaa koodia, joka vie aikaa
$O(1)$ tai $O(\log n)$.
Algoritmi voi myös järjestää aineistoa,
koska tehokkaat järjestämisalgoritmit vievät aikaa $O(n \log n)$.
Kovin paljon muuta tehokas algoritmi ei sitten voikaan tehdä.
Tämä rajoittaa paljon, mitä aineksia voimme laittaa algoritmiin,
mutta voimme ajatella asiaa myös myönteisesti:
vaatimus tehokkuudesta rajaa pois suuren määrän lähestymistapoja,
eli meidän on helpompaa löytää hyvä algoritmi,
kun vaihtoehtojen määrä on pienempi.

Tavallinen tilanne algoritmien suunnittelussa on,
että pystymme ratkaisemaan annetun ongelman
helposti $O(n^2)$-ajassa ensimmäisellä mieleen tulevalla algoritmilla,
mutta tarvitsisimme tehokkaamman algoritmin,
joka toimisi ajassa $O(n)$ tai $O(n \log n)$.
Kokemus on osoittanut, että tämä on hyvä tilanne:
yleensä \emph{pystymme} tehostamaan
tavalla tai toisella algoritmia,
kunhan mietimme huolellisesti asiaa.
Donald Knuth kuvailee samaa ilmiötä teoksessaan
\emph{The Art of Computer Programming} (osa 4A, esipuhe):

\begin{quote}
Starting about 1970, computer scientists began to experience
a phenomenon that we called ''Floyd's Lemma'':
Problems that seemed to need $n^3$ operations could actually be
solved in $O(n^2)$; problems that seemed to require $n^2$
could be handled in $O(n \log n)$; and $n \log n$ was often
reducible to $O(n)$.
\end{quote}

Tarkastellaan esimerkkinä seuraavaa tehtävää:
Annettuna on taulukko, joka sisältää luvut $1,2,\dots,n$
jossakin järjestyksessä,
ja haluamme kerätä taulukon luvut järjestyksessä pienimmästä suurimpaan.
Joka kierroksella käym\-me läpi taulukon vasemmalta
oikealle ja keräämme mahdollisimman monta seuraavaa lukua.
Montako kierrosta tarvitsemme yhteensä?
Esimerkiksi taulukossa $[4,3,1,5,2]$
tarvitsemme kolme kierrosta:
ensimmäisellä kierroksella keräämme luvut $1$ ja $2$,
toisella luvun $3$ ja kolmannella luvut $4$ ja $5$.

Voimme ratkaista tehtävän helposti $O(n^2)$-ajassa
simuloimalla lukujen keräämistä tehtävänannon kuvaamalla tavalla:

\begin{code}
luku = 1
laskuri = 0
while luku <= n
    laskuri++
    for i = 0 to n-1
        if taulu[i] == luku
            luku++
print(laskuri)
\end{code}

Tässä muuttuja \texttt{luku} kertoo,
minkä luvun haluamme kerätä seuraavaksi,
ja muuttuja \texttt{laskuri} laskee,
montako kierrosta tarvitaan.
Kierroksia tarvitaan aina korkeintaan $n$,
koska saamme kerättyä joka kierroksella
ainakin yhden luvun,
joten algoritmi toimii ajassa $O(n^2)$.

Kuinka voisimme sitten tehostaa algoritmia niin,
että se veisi aikaa vain $O(n)$ tai $O(n \log n)$?
Yllä olevan algoritmin hitaus johtuu pohjimmiltaan siitä,
että algoritmilla menee kauan aikaa löytää,
missä kohdassa taulukossa on seuraava luku,
jonka haluamme kerätä.
Niinpä jotta voimme ratkaista tehtävän tehokkaasti,
meidän täytyy jollakin tavalla löytää seuraava kerät\-tävä luku nopeammin.
Kätevä ratkaisu tähän on luoda aputaulukko \texttt{kohta},
joka kertoo jokaisen luvun kohdan:

\begin{code}
for i = 0 to n-1
    kohta[taulu[i]] = i
\end{code}

Tämän taulukon avulla saamme selville $O(1)$-ajassa,
missä kohdassa taulukossa on seuraava kerättävä luku.
Entä mistä tiedämme, montako kierrosta tarvitsemme?
Meidän täytyy aloittaa uusi kierros aina silloin,
kun viimeksi keräämämme luku on myöhemmin taulukossa
kuin seuraava kerättävä luku.
Niinpä voimme laskea kierrosten määrän näin:

\begin{code}
laskuri = 1
for i = 2 to n
    if kohta[i-1] > kohta[i]
        laskuri++
print(laskuri)
\end{code}

Tuloksena on algoritmi, jossa on kaksi silmukkaa,
joista molemmat vievät aikaa vain $O(n)$.
Niinpä algoritmin aikavaativuus on $O(n)$,
eli olemme saavuttaneet tavoitteemme.

\section{Ahneet algoritmit}

Tehokkaan algoritmin saaminen aikaan vaatii usein,
että pystymme tekemään algoritmissa jotain \emph{ahneesti}.
Tämä tarkoittaa, että meidän ei tarvitse käydä läpi
kaikkia mahdollisia ratkaisuja vaan pystymme rakentamaan
ratkaisun suoremmin käsittelemällä syötteen sopivassa järjestyksessä.

Ahneen algoritmin idea on yleensä yksinkertainen ja
se on helppoa toteuttaa.
Vaikeutena on kuitenkin keksiä ahne algoritmi,
joka toimii oikein kaikissa tilanteissa.
Koska ahne algoritmi muodostaa vastauksen suoraan
käymättä läpi kaikkia vaihtoehtoja, on suuri riski,
että se ei löydä aina parasta ratkaisua.
Ennen kuin voimme käyttää ahnetta algoritmia luottavaisin mielin,
meidän täytyykin vakuuttua sen toimivuudesta.

\subsection{Esimerkki: Asunnot}

Tarkastellaan esimerkkinä seuraavaa tehtävää:
Meillä on tiedot $n$ vapaasta asunnosta sekä
$m$ asunnon hakijasta.
Tiedämme jokaisen asunnon vuokran,
ja lisäksi kukin asunnon hakija on ilmoittanut
ylärajan, kuinka suurta vuok\-raa hän voi maksaa.
Miten voimme jakaa asunnot niin,
että mahdollisimman moni hakija saa asunnon?

Voimme ratkaista tehtävän ahneella algoritmilla,
joka käy läpi hakijat järjestyksessä vuokran
ylärajan mukaan pienimmästä suurimpaan.
Jokaisen hakijan kohdalla tarkastamme,
onko jäljellä asuntoa, jonka hän voi vuokrata,
ja jos on, annamme kyseisen asunnon hänelle.
Jos mahdollisia asuntoja on useita,
valitsemme jonkin niistä.
Tämän jälkeen siirrymme seuraavaan hakijaan
ja jatkamme samalla tavalla.

Esimerkiksi jos asuntojen vuokrat ovat $[600,650,700]$
ja vuokraajien ylä\-rajat ovat $[500,600,600,800]$,
toimimme seuraavasti:
Koetamme ensin löytää asunnon vuokraajalle,
jonka vuokran yläraja on $500$.
Mitään tällaista asuntoa ei ole, joten siirrymme eteenpäin.
Seuraavaksi vuoroon tulee vuokraaja, jonka vuokran yläraja on $600$,
ja annamme hänelle asunnon, jonka vuokra on $600$.
Sitten toinen vuokraaja, jonka yläraja on $600$,
ei saa asuntoa (koska ainoa näin halpa asunto meni jo),
ja lopuksi vuokraaja, jonka yläraja on $800$
saa jommankumman jäljellä olevista asunnoista.

Miksi tämä algoritmi toimii?
Ahneissa algoritmeissa auttaa usein ajatella,
mitä tapahtuu, jos \emph{emme} tee jotain valintaa.
Jos saatavilla olisi vuokraajalle $x$ sopiva asunto,
mutta emme anna asuntoa hänelle,
joku myöhemmin käsiteltävä vuokraaja $y$ voi saada kyseisen asunnon.
Lopulta saamme aikaan jonkin ratkaisun, jossa
vuokraajalla $x$ ei ole asuntoa ja vuokraajalla $y$ on asunto.
Kuitenkin voimme \emph{muuttaa} tätä ratkaisua niin,
että ratkaisu säilyy muuten samana, mutta vuokraajan $y$
asunnon saakin vuokraaja $x$.
Tuloksena on ratkaisu, joka on yhtä hyvä kuin alkuperäinen ratkaisu.
Niinpä emme saa koskaan aikaan parempaa ratkaisua
jättämällä vuokraajan $x$ ilman asuntoa,
mikä tarkoittaa, että voimme yhtä hyvin antaa asunnon alunperin
vuokraajalle $x$ ja ahne algoritmi toimii.

\section{Binäärihaun sovellukset}

\emph{Binäärihaku} on tekniikka, joka pelastaa meidät monesta
kiipelistä algoritmien suunnittelussa.
Parhaiten tunnettu binäärihaun käyttötarkoitus on alkion
etsiminen järjestetystä taulukosta ajassa $O(\log n)$.
Tämä on kuitenkin vain alkusoittoa sille,
mitä binäärihaun avulla pystyy tekemään ja mikä on sen
todellinen merkitys algoritmien suunnittelussa.

\subsection{Muutoskohdan etsiminen}

Oletetaan, että meillä on funktio $f$,
jolle pätee, että $f(x)=0$, kun $x<k$,
ja $f(x)=1$, kun $x \ge k$.
Binäärihaun avulla voimme etsiä tehokkaasti,
mikä on funktion \emph{muutoskohta} $k$
eli ensimmäinen kohta, jossa funktio saa arvon $1$.
Seuraava koodi toteuttaa haun olettaen,
että $k$ on välillä $1 \dots N$:


\begin{code}
int a = 1, b = N;
while (a < b) {
    int u = (a+b)/2;
    if (f(u) == 0) a = u+1;
    if (f(u) == 1) b = u;
}
int k = a;
\end{code}

Haun joka vaiheessa tiedämme, että muutoskohta on välillä $[a,b]$.
Laskemme keskikohdan $u=(a+b)/2$ ja tutkimme funktion arvoa kohdassa $u$.
Jos $f(u)=0$, niin tiedämme, että muutoskohta on välillä $[u+1,b]$.
Jos taas $f(u)=1$, niin muutoskohdan on oltava välillä $[a,u]$.
Lopulta välillä on vain yksi alkio, jolloin olemme löytäneet muutoskohdan.
Koska välin koko puolittuu joka askeleella,
kutsumme $O(\log N)$ kertaa funktiota $f$.

Mitä hyötyä on siitä, että löydämme tehokkaasti muutoskohdan?
Tarkastellaan esimerkkinä tehtävää, jossa käytössämme on $n$ konetta
ja haluamme valmistaa niiden avulla $m$ tavaraa.
Tiedossamme on myös arvot $[x_1,x_2,\dots,x_n]$:
jokaisesta koneesta tieto, montako minuuttia vie aikaa valmistaa
yksi tavara konetta käyttäen.
Haluamme löytää aikataulun, jota seuraamalla pystymme valmistamaan
$m$ tavaraa mahdollisimman nopeasti.
Esimerkiksi jos $n=3$, $m=7$ ja koneiden nopeudet ovat $[2,3,7]$,
paras aikataulu on kuvassa \ref{fig:optkon}.
Sitä käyttäen tavaroiden muodostaminen vie aikaa $8$ minuuttia.
Käynnistämme koneen 1 neljästi hetkinä 0, 2, 4 ja 6,
koneen 2 kahdesti hetkinä 0 ja 3
ja koneen 3 kerran hetkenä 0.
Aikaa kuluu $8$ minuuttia, koska viimeisenä pysähtyy kone 1 hetkenä 8.

\begin{figure}
\center
\begin{tikzpicture}[scale=0.7]
\draw[->] (-1,1.5) -- (10,1.5);
\foreach \x in {0,...,8} \draw (\x,1.40) -- (\x,1.60);
\foreach \x in {0,...,8} \node at (\x,2) {\scriptsize $\x$};
\node at (-2,0) {kone $1$};
\draw[|-|] (0.05,0) -- (1.95,0);
\draw[|-|] (2.05,0) -- (3.95,0);
\draw[|-|] (4.05,0) -- (5.95,0);
\draw[|-|] (6.05,0) -- (7.95,0);
\node at (-2,-1.5) {kone $2$};
\draw[|-|] (0.05,-1.5) -- (2.95,-1.5);
\draw[|-|] (3.05,-1.5) -- (5.95,-1.5);
\node at (-2,-3) {kone $3$};
\draw[|-|] (0.05,-3) -- (6.95,-3);
\end{tikzpicture}
\caption{Optimaalinen tapa valmistaa 7 tavaraa vie 8 sekuntia,
kun koneiden nopeudet ovat $[2,3,7]$.}
\label{fig:optkon}
\end{figure}

Voimme pukea tehtävän binäärihaulle sopivaan muotoon niin,
että $f(x)=1$ tarkalleen silloin, kun voimme muodostaa
\emph{ainakin} $m$ tavaraa ajassa $x$.
Tällöin funktion muutoskohta $k$ vastaa tehtävän ratkaisua.
Entä miten voimme laskea funktion $f$ arvon?
Jos meillä on $u$ minuuttia aikaa ja jollakin koneella kestää $x_i$
minuuttia valmistaa yksi tavara, pystymme valmistamaan
$\lfloor u/x_i \rfloor$ tavaraa kyseistä konetta käyttäen.
Kun sitten käytössämme on kaikki koneet,
pystymme valmistamaan yhteensä
\[ s = \sum_{i=1}^n \lfloor u/x_i \rfloor \]
tavaraa. Niinpä $f(u)=0$, jos $s<m$,
ja $f(u)=1$, jos $s \ge m$. Voimme toteuttaa tämän seuraavasti:

\begin{code}
int f(int u) {
    int s = 0;
    for (int i = 1; i <= n; i++) s += u/x[i];
    return (s < m) ? 0 : 1;
}
\end{code}

Voimme kytkeä tämän metodin suoraan binäärihakuun,
jolloin tuloksena on tehokas algoritmi tehtävän ratkaisemiseen.
Meidän täytyy kuitenkin vielä valita arvo $N$,
joka on jokin yläraja kohdalle $k$.
Tässä tehtävässä helppo valinta on
\[N = x_1 \cdot m,\]
mikä vastaa ratkaisua, jossa käytämme vain ensimmäistä konetta.
On varmaa, että oikea $k$:n arvo on korkeintaan $N$,
joten binäärihaku kutsuu $O(\log N)$ kertaa metodia $\texttt{f}$.
Koska jokainen metodin kutsu vie aikaa $O(n)$,
tuloksena on algoritmi, jonka aikavaativuus on $O(n \log N)$.

Huomaa, että $\log N$ on käytännössä pieni luku riippumatta
siitä, kuinka suuri luku $N$ on.
Niinpä meidän ei tarvitse murehtia siitä,
kuinka suuria $x_1$ ja $m$ ovat,
vaan voimme luottaa siihen, että algoritmi on tehokas.

\subsection{Alitaulukot, osa 1}

Tarkastellaan sitten tehtävää, jossa annettuna on $n$
positiivista kokonaislukua sisältävä taulukko ja lisäksi kokonaisluku $x$.
Haluamme selvittää, monessako yhtenäisessä alitaulukossa
lukujen summa on $x$.
Esimerkiksi jos taulukko on $[3,2,1,1,3,1]$ ja $x=4$,
niin halutut alitaulukot ovat $[2,1,1]$, $[1,3]$ ja $[3,1]$,
eli vastaus on tässä tapauksessa $3$.

Voimme ratkaista tehtävän helposti ajassa $O(n^2)$
käymällä läpi kaikki yhtenäiset alitaulukot seuraavasti:

\begin{code}
int laskuri = 0;
for (int i = 0; i < n; i++) {
    int summa = 0;
    for (int j = i; j < n; j++) {
        summa += taulu[j];
        if (summa == x) laskuri++;
    }
}
System.out.println(laskuri);
\end{code}

Binäärihaun avulla voimme kuitenkin parantaa algoritmia niin,
että aikaa kuluu vain $O(n \log n)$.
Ideana on korvata koodin sisempi silmukka
binääri\-haulla, joka etsii tehokkaasti kohdasta $i$
alkavan alitaulukon, jonka summa on $x$, jos tällainen alitaulukko on olemassa.
Voimme käyttää binäärihakua, koska tiedämme, että taulukon kaikki
luvut ovat positiivisia, jolloin mitä enemmän lukuja laitamme alitaulukkoon,
sitä suurempi sen summa on.
Niinpä voimme etsiä ensimmäisen kohdan $j$,
jossa välin $[i,j]$ lukujen summa on ainakin $x$.
Jos summa on tasan $x$, olemme löytäneet halutun alitaulukon,
ja muuten tällaista alitaulukkoa ei ole olemassa.

Jotta voimme toteuttaa tehokkaan ratkaisun,
tarvitsemme kuitenkin vielä yhden aineksen:
meidän täytyy pystyä laskemaan algoritmin aikana tehokkaasti,
mikä on lukujen summa taulukon välillä $[a,b]$.
Tarvittava tietorakenne on \emph{summataulukko},
jossa kohdassa $k$ on taulukon
lukujen summa taulukon alusta kohtaan $k$ asti.
Seuraava koodi muodostaa taulukosta summataulukon ajassa $O(n)$:

\begin{code}
st[0] = taulu[0];
for (int i = 1; i < n; i++) {
    st[i] = st[i-1]+taulu[i];
}
\end{code}

Tämän jälkeen pystymme laskemaan $O(1)$-ajassa,
mikä on taulukon lukujen summa välillä $[a,b]$:

\begin{code}
int summa(int a, int b) {
    if (a == 0) return st[b];
    else return st[b]-st[a-1];
}
\end{code}

Nyt voimme toteuttaa binäärihaun seuraavasti:

\begin{code}
int laskuri = 0;
for (int i = 0; i < n; i++) {
    int a = i, b = n-1;
    while (a < b) {
        int u = (a+b)/2;
        if (summa(i,u) < x) a = u+1;
        else b = u;
    }
    if (summa(i,a) == x) laskuri++;
}
System.out.println(laskuri);
\end{code}

Jokaisessa kohdassa $i$ etsimme binäärihaulla väliltä $[i,n-1]$
ensimmäisen kohdan, jossa alitaulukon summa on ainakin $x$.
Sitten tarkastamme, onko summa tasan $x$,
ja jos on, kasvatamme laskuria yhdellä.
Tuloksena olevan algoritmin aikavaativuus on $O(n \log n)$,
koska jokainen binäärihaku vie summataulukon ansiosta
aikaa vain $O(\log n)$.

\section{Tasoitettu analyysi}

Tähän mennessä olemme arvioineet algoritmien tehokkuutta
lähinnä määrit\-tämällä jokaiselle silmukalle ylärajan,
montako kertaa siinä olevaa koodia suoritetaan.
Tämä onkin yleensä hyvä tapa laskea aikavaativuus,
mutta joskus ongelmaksi voi tulla, että silmukan kierrosten
määrä vaihtelee algoritmin eri vaiheissa eikä yläraja
anna oikeaa kuvaa tehokkuudesta.

Seuraavaksi tutustumme tekniikkaan nimeltä
\emph{tasoitettu analyysi}, jossa koetamme arvioida tarkemmin,
montako kertaa silmukassa olevaa koodia suoritetaan
\emph{yhteensä} algoritmin aikana.
Tämän avulla pystymme joskus huomaamaan, että algoritmi
toimii tehokkaammin kuin vaikuttaa ensin.

\subsection{Alitaulukot, osa 2}

Palaamme aluksi tehtävään, jossa meille on annettu
$n$ positiivisen kokonaisluvun taulukko ja haluamme laskea,
monenko yhtenäisen alitaulukon summa on $x$.
Olemme jo ratkaisseet tehtävän ajassa $O(n \log n)$
binäärihaun ja summataulukon avulla,
mutta nyt ratkaisemme tehtävän vielä tehokkaammin
ajassa $O(n)$ esimerkkinä tasoitetusta analyysista.

Ideana on, että meillä on kaksi muuttujaa $i$ ja $j$,
jotka osoittavat taulukkoon.
Muuttujat aloittavat taulukon alusta,
ja jokaisella vuorolla $i$ siirtyy askeleen oikealle
ja $j$ siirtyy oikealle niin kauan, kunnes välin $[i,j]$
lukujen summa on ainakin $x$.
Jos lukujen summa on tasan $x$, olemme löytäneet yhden
alitaulukon, jonka summa on $x$.
Seuraava koodi toteuttaa algoritmin:

\begin{code}
int j = -1;
int summa = 0;
int laskuri = 0;
for (int i = 0; i < n; i++) {
    while (j+1 < n && summa < x) {
        j++;
        summa += taulu[j];
    }
    if (summa == x) laskuri++;
    summa -= taulu[i];
}
System.out.println(laskuri);
\end{code}

Tästä koodista on ensin näkemältä vaikeaa määrittää algoritmin
aikavaativuutta, koska ei ole varmaa, montako kierrosta
\texttt{while}-silmukkaa suoritetaan milloinkin.
Saattaa olla, että jollakin kertaa silmukkaa ei suoriteta lainkaan
mutta toisella kertaa $O(n)$ kierrosta.
Koska silmukkaa suoritetaan aina enintään $O(n)$ kierrosta,
saamme algoritmille aikavaativuuden $O(n^2)$,
mutta antaako tämä hyvän kuvan algoritmista?

Voimme analysoida algoritmia tarkemmin kiinnittämällä huomiota
siihen, miten muuttujan $j$ arvo muuttuu algoritmissa.
Muuttujan arvo on aluksi $-1$,
se kasvaa yhdellä jokaisella \texttt{while}-silmukan kierroksella
ja silmukkaan mennään vain, jos arvo on enintään $n-1$.
Niinpä voimme päätellä, että silmukassa oleva koodi suoritetaan \emph{yhteensä}
$O(n)$ kertaa, mikä tarkoittaa sitä,
että koko algoritmin aikavaativuus on vain $O(n)$.

\subsection{Lähin pienempi edeltäjä}

Tasoitettuun analyysiin liittyy usein jokin tietorakenne,
jonka operaatioiden määrää haluamme arvioida.
Näin on myös seuraavassa tehtävässä:

Annettuna on taulukko, jossa on $n$ kokonaislukua,
ja haluamme muodostaa toisen taulukon,
jossa on jokaisen luvun \emph{lähin pienempi edeltäjä}.
Tämä tarkoittaa, että haluamme löytää jokaiselle taulukon luvulle
sitä pienemmän luvun, joka on mahdollisimman lähellä aiemmin taulukossa.
Esimerkiksi taulukon $[1,4,5,2,3,2]$
lähimmät pienemmät edeltäjät ovat $[-,1,4,1,2,1]$.
Koska luvulla $1$ ei ole pienempää edeltäjää,
sen kohdalla on merkki $-$.

Seuraavassa on $O(n^2)$-algoritmi, joka etsii
lähimmät pienemmät edeltäjät:

\begin{code}
for (int i = 0; i < n; i++) {
    for (int j = i-1; j >= 0; j--) {
        if (taulu[j] < taulu[i]) {
            edeltaja[i] = taulu[j];
            break;
        }
    }
}
\end{code}

Ratkaisemme tehtävän tehokkaasti pitämällä yllä \emph{pinoa},
jossa on kasvava lista taulukon lukuja.
Pino on tietorakenne, jossa voimme lisätä alkion pinon päälle
ja hakea tai poistaa pinon ylimmän alkion.
Voisimme toteuttaa pinon listana,
mutta Javassa on myös erikoistunut tietorakenne \texttt{Stack},
jota käytämme seuraavassa koodissa:

\begin{code}
Stack<Integer> pino = new Stack<>();
for (int i = 0; i < n; i++) {
    while (!pino.empty() && pino.peek() >= taulu[i]) {
        pino.pop();
    }
    if (!pino.empty()) {
        edeltaja[i] = pino.peek();
    }
    pino.push(taulu[i]);
}
\end{code}

Metodi \texttt{push} lisää alkion pinoon,
\texttt{peek} hakee ylimmän alkion ja \texttt{pop}
poistaa ylimmän alkion.
Ideana on, että säilytämme pinossa kasvavassa järjestyk\-sessä
ehdokkaita tulevien lukujen lähimmiksi pienimmiksi edeltäjiksi.
Jokaisessa taulukon kohdassa poistamme
pinosta lukuja, kunnes pinon ylin luku on pienempi kuin nykyinen luku
tai pino on tyhjä.
Jos pino ei ole tämän jälkeen tyhjä, sen ylin luku on nykyisen luvun
lähin pienempi edeltäjä.
Lopuksi lisäämme nykyisen luvun pinoon päälle.

Algoritmin tehokkuus riippuu siitä, montako kertaa suoritamme
\texttt{while}-silmukassa olevan koodin.
Oleellinen havainto on, että voimme poistaa pinosta
korkeintaan niin monta alkiota kuin olemme lisänneet siihen,
eli emme voi kutsua \texttt{pop}-metodia useammin kuin \texttt{push}-metodia.
Koska lisäämme pinoon $n$ alkiota, suoritamme \texttt{while}-silmukkaa
siis enintään $n$ kierrosta.
Tämän ansiosta algoritmin aikavaativuus on $O(n)$.