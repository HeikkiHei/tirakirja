\chapter{Algoritmien suunnittelu}

Kuinka voi suunnitella hyvän algoritmin?
On selvää, ettei tähän kysymykseen ole yhtä helppoa vastausta.
Yhtä hyvin voisi kysyä, kuinka voi kirjoittaa hyvän kirjan
tai säveltää hyvää musiikkia.
Algoritmien suunnittelu on taito, jonka oppiminen vie aikaa.

Tässä luvussa keskitymme erityisesti tavoitteeseen
saada aikaan algoritmi, jonka aikavaativuus on $O(n)$ tai $O(n \log n)$.
Tällaisen algoritmin etuna on, että se toimii tehokkaasti
myös silloin, kun syötteen koko $n$ on suuri.
Tavoitteen asettaminen etukäteen on hyödyllistä,
koska kun tiedämme tavoitteen, voimme ottaa sen suunnittelumme
lähtökohdaksi ja rajata sen avulla mahdollisia
lähestymistapoja, joita voimme käyttää.

\section{Algoritmin tehostaminen}

Millainen on algoritmi, joka vie aikaa $O(n)$ tai $O(n \log n)$?
Tämä tarkoittaa,
että kun algoritmille annetaan syötteenä $n$ alkiota,
se saa käyttää jokaisen alkion käsittelyyn
vain pienen määrän aikaa.
Niinpä algoritmissa tulisi esiintyä seuraavan kaltaisia silmukoita:

\begin{code}
for i = 0 to n-1
    // tee jotain nopeaa
\end{code}

Tässä ''jotain nopeaa'' tarkoittaa koodia, joka vie aikaa
$O(1)$ tai $O(\log n)$.
Algoritmi voi myös järjestää aineistoa,
koska tehokkaat järjestämisalgoritmit vievät aikaa $O(n \log n)$.
Kovin paljon muuta tehokas algoritmi ei sitten voikaan tehdä.
Tämä rajoittaa paljon, mitä aineksia voimme laittaa algoritmiin,
mutta voimme ajatella asiaa myös myönteisesti:
vaatimus tehokkuudesta rajaa pois suuren määrän lähestymistapoja,
eli meidän on helpompaa löytää hyvä algoritmi,
kun vaihtoehtojen määrä on pienempi.

Tavallinen tilanne algoritmien suunnittelussa on,
että pystymme ratkaisemaan annetun ongelman
helposti $O(n^2)$-ajassa ensimmäisellä mieleen tulevalla algoritmilla,
mutta haluaisimme tehokkaamman algoritmin,
joka toimisi ajassa $O(n)$ tai $O(n \log n)$.
Kokemus on osoittanut, että tämä on hyvä tilanne:
yleensä \emph{pystymme} tehostamaan
tavalla tai toisella algoritmia,
kunhan mietimme huolellisesti asiaa.
Donald Knuth kuvailee samaa ilmiötä teoksessaan
\emph{The Art of Computer Programming} (osa 4A, esipuhe):

\begin{quote}
Starting about 1970, computer scientists began to experience
a phenomenon that we called ''Floyd's Lemma'':
Problems that seemed to need $n^3$ operations could actually be
solved in $O(n^2)$; problems that seemed to require $n^2$
could be handled in $O(n \log n)$; and $n \log n$ was often
reducible to $O(n)$.
\end{quote}

Tarkastellaan esimerkkinä seuraavaa tehtävää:
Annettuna on taulukko, joka sisältää luvut $1,2,\dots,n$
jossakin järjestyksessä,
ja haluamme kerätä luvut järjestyksessä pienimmästä suurimpaan.
Joka kierroksella käym\-me läpi taulukon sisällön vasemmalta
oikealle ja keräämme mahdollisimman monta seuraavaa lukua.
Montako kierrosta tarvitsemme yhteensä?
Esimerkiksi taulukossa $[4,3,1,5,2]$
tarvitsemme kolme kierrosta:
ensimmäisellä kierroksella keräämme luvut $1$ ja $2$,
toisella luvun $3$ ja kolmannella luvut $4$ ja $5$.

Voimme ratkaista tehtävän helposti $O(n^2)$-ajassa
simuloimalla lukujen keräämistä tehtävänannon kuvaamalla tavalla:

\begin{code}
luku = 1
laskuri = 0
while luku <= n
    laskuri++
    for i = 0 to n-1
        if taulu[i] == luku
            luku++
print(laskuri)
\end{code}

Tässä muuttuja \texttt{luku} kertoo,
minkä luvun haluamme kerätä seuraavaksi,
ja muuttuja \texttt{laskuri} laskee,
montako kierrosta tarvitaan.
Kierroksia tarvitaan aina korkeintaan $n$,
koska saamme kerättyä joka kierroksella
ainakin yhden luvun,
joten algoritmi toimii ajassa $O(n^2)$.

Kuinka voisimme sitten tehostaa algoritmia niin,
että se veisi aikaa vain $O(n)$ tai $O(n \log n)$?
Yllä olevan algoritmin hitaus johtuu pohjimmiltaan siitä,
että algoritmilla menee kauan aikaa löytää,
missä kohdassa taulukossa on seuraava luku,
jonka haluamme kerätä.
Niinpä jotta voimme ratkaista tehtävän tehokkaasti,
meidän täytyy jollakin tavalla löytää seuraava kerät\-tävä luku nopeammin.
Kätevä ratkaisu tähän on luoda aputaulukko \texttt{kohta},
joka kertoo jokaisen luvun kohdan:

\begin{code}
for i = 0 to n-1
    kohta[taulu[i]] = i
\end{code}

Tämän taulukon avulla saamme selville $O(1)$-ajassa,
missä kohdassa taulukkoa on seuraava kerättävä luku.
Entä mistä tiedämme, montako kierrosta tarvitsemme?
Meidän täytyy aloittaa uusi kierros aina silloin,
kun viimeksi keräämämme luku on myöhemmin taulukossa
kuin seuraava kerättävä luku.
Niinpä voimme laskea kierrosten määrän näin:

\begin{code}
laskuri = 1
for i = 2 to n
    if kohta[i-1] > kohta[i]
        laskuri++
print(laskuri)
\end{code}

Tuloksena on algoritmi, jossa on kaksi silmukkaa,
joista molemmat vievät aikaa vain $O(n)$.
Niinpä algoritmin aikavaativuus on $O(n)$,
eli olemme saavuttaneet tavoitteemme.

\section{Algoritmien aineksia}

Seuraavaksi käymme läpi tarkemmin \emph{aineksia},
joita näkee usein tehokkaissa algoritmeissa.
Nämä ainekset muodostavat hyvän perustan algoritmien
suunnittelemiseen: kun saamme vastaamme uuden ongelman,
voimme miettiä, voisimmeko hyödyntää aineksia jotenkin
ongelman ratkaisemisessa.

\subsection{Järjestäminen}

Tehokas algoritmi perustuu usein tavalla tai toisella järjestämiseen.
Monessa tilanteessa meidän on helpompaa lähestyä ongelmaa,
jos voimme olettaa, että syöte on järjestyksessä.
Järjestäminen vie aikaa $O(n \log n)$, joten voimme käyttää sitä
huoletta tehokkaassa algoritmissa.

Jotta voimme käyttää järjestämistä, meidän täytyy usein havaita
ongelmasta jokin ominaisuus, jonka ansiosta voimme ratkaista
ongelman \emph{ahneella} algoritmilla.
Ahne algoritmi valitsee joka askeleella parhaalta tuntuvan
vaihtoehdon eikä tutki muita vaihtoehtoja.
Meidän täytyy kuitenkin olla varmoja, että saamme oikean ratkaisun tällä tavalla.

Tarkastellaan esimerkkinä tehtävää, jossa haluamme laskea
tutkijan \emph{$h$-indeksin}. Tämä on suurin luku $x$, jolle pätee,
että tutkijalla on $x$ julkaisua, joihin on viitattu ainakin $x$ kertaa.
Esimerkiksi jos tutkijalla on kolme julkaisua,
joiden viittausmäärät ovat $[5,1,3]$, hänen $h$-indeksinsä on $2$:
hänellä on kaksi julkaisua, joihin on viitattu ainakin kahdesti.

Tässä tehtävässä hyödyllinen havainto on, että meidän kannattaa aina
tarkastella tutkijan \emph{viitatuimpia} julkaisuja.
Jos tutkijan $h$-indeksi on $x$, voimme tarkastella vain $x$ viitatuinta
julkaisua, ja kaikissa niissä viittausmäärän on oltava ainakin $x$.
Tämä havainto johtaa ahneeseen algoritmiin: järjestämme ensin
viittausmäärät ja etsimme sitten suurimman arvon $x$,
jolle pätee, että $x$ viitatuimman julkaisun joukossa vähiten viitatussa
julkaisussa on ainakin $x$ viittausta. Voimme toteuttaa algoritmin seuraavasti:

\begin{code}
sort(viittaukset)
h_indeksi = 0
for x = 1 to n
    if viittaukset[n-x] >= x
        h_indeksi = x
\end{code}

Taulukon järjestäminen vie aikaa $O(n \log n)$ ja for-silmukka vie aikaa $O(n)$,
joten algoritmi toimii ajassa $O(n \log n)$.

\subsection{Tietorakenteet}

Olemme tutustuneet jo kirjassa moniin tietorakenteisiin:
listoihin, hajautustauluun, binäärihakupuuhun ja kekoon.
Näissä tietorakenteissa kannattaa kiinnittää erityisesti huomiota siihen,
mitkä operaatiot toimivat tehokkaasti $O(1)$- tai $O(\log n)$-ajassa.
Nämä ovat operaatioita, joita voimme käyttää tehokkaissa algoritmeissa.

Tarkastellaan esimerkkinä tehtävää, jossa haluamme laskea,
monellako tavalla voimme valita taulukosta yhtenäisen osataulukon,
jossa lukujen summa on $x$.
Voimme alkajaisiksi ratkaista tehtävän suoraviivaisesti ajassa $O(n^2)$
käymällä läpi kaikki osataulukot kahdella silmukalla:

\begin{code}
laskuri = 0
for i = 0 to n-1
    summa = 0
    for j = i to n-1
        summa += taulu[j]
        if summa == x:
            laskuri++
\end{code}

Entä kuinka voisimme ratkaista tehtävän tehokkaasti?
Tässä meitä auttaa muotoilla hieman toisin, mitä tarkoittaa,
että osataulukon summa on $x$.
Merkitään $s(i)$:llä osataulukon summaa taulukon alusta
kohtaan $i$ asti, ja oletetaan lisäksi, että $s(-1)=0$.
Tätä merkintää käyttäen osataulukon summa
kohdasta $a$ kohtaan $b$ on
\[s(b)-s(a-1),\]
eli meidän riittää itse asiassa keskittyä vain taulukon alusta
alkavien osataulukoiden summiin.

Koska haluamme saada tehokkaan algoritmin,
hyvä tavoite olisi käydä taulukko läpi vain kerran.
Kun olemme taulukon kohdassa $i$,
monessako tähän kohtaan päättyvässä osataulukossa
lukujen summa on $x$?
Tämä tarkoittaa, että haluamme etsiä kohdat $j<i$,
joille pätee
\[s(i)-s(j-1)=x\]
eli
\[s(j-1)=s(i)-x.\]
Tämä onnistuu tehokkaasti, kun pidämme taulukon läpikäynnissä
kirjaa, montako kertaa mikäkin summa on esiintynyt taulukon alkuosassa.
Voimme toteuttaa algoritmin seuraavasti:

\begin{code}
summat[0] = 1
laskuri = 0
summa = 0
for i = 0 to n-1
    laskuri += summat[taulu[i]-x]
    summa += taulu[i]
    summat[summa]++
\end{code}

Tässä rakenne \texttt{summat} pitää kirjaa,
montako kertaa mikäkin alkuosan summa on esiintynyt tähän mennessä.
Koska summat voivat olla suuria, emme voi käyttää tavallista taulukkoa,
mutta voimme sen sijaan käyttää hajautustauluun tai binäärihakupuuhun
perustuvaa hakemistoa.
Näin saamme aikaan ratkaisun, joka vie aikaa $O(n)$ tai $O(n \log n)$
riippuen valitusta tietorakenteesta.

\subsection{Binäärihaku}

Binäärihaun tunnetuin käyttötarkoitus on alkion etsiminen
järjestetystä taulukosta ajassa $O(\log n)$.
Tämä on kuitenkin vain alkusoittoa sille,
mitä binää\-rihaulla pystyy tekemään ja mikä on sen
merkitys algoritmien suunnittelussa.
Binääri\-haun todellinen hyöty piilee siinä,
että pystymme etsimään sen avulla tehokkaasti funktion \emph{muutoskohdan}.

Oletetaan, että meillä on funktio $\texttt{ok}(x)$,
joka kertoo, onko $x$ kelvollinen ratkaisu tehtävään.
Lisäksi pätee $\texttt{ok}(x)=\texttt{false}$, kun $x<k$,
ja $\texttt{ok}(x)=\texttt{true}$, kun $x \ge k$.
Binäärihaun avulla voimme etsiä tehokkaasti,
mikä on funktion muutoskohta $k$
eli ensimmäinen kohta, jossa funktio saa arvon \texttt{true}.
Seuraava koodi toteuttaa haun, kun oletamme, että $k$ on välillä $1 \dots N$:

\begin{code}
a = 1, b = N
while a < b
    u = (a+b)/2
    if ok(u)
        b = u
    else
        a = u+1
k = a
\end{code}

Haun joka vaiheessa tiedämme, että muutoskohta on välillä $[a,b]$.
Laskemme keskikohdan $u=(a+b)/2$ ja tutkimme funktion arvoa kohdassa $u$.
Jos pätee $\texttt{ok}(u)$, niin muutoskohdan on oltava välillä $[a,u]$,
ja muuten sen täytyy olla välillä $[u+1,b]$.
Lopulta välillä on vain yksi alkio, jolloin olemme löytäneet muutoskohdan.
Koska välin koko puolittuu joka askeleella,
kutsumme funktiota \texttt{ok} yhteensä $O(\log N)$ kertaa.

\begin{figure}
\center
\begin{tikzpicture}[scale=0.6]
\draw[->] (-1,1.5) -- (10,1.5);
\foreach \x in {0,...,8} \draw (\x,1.40) -- (\x,1.60);
\foreach \x in {0,...,8} \node at (\x,2) {\scriptsize $\x$};
\node at (-2,0) {kone $1$};
\draw[|-|] (0.05,0) -- (1.95,0);
\draw[|-|] (2.05,0) -- (3.95,0);
\draw[|-|] (4.05,0) -- (5.95,0);
\draw[|-|] (6.05,0) -- (7.95,0);
\node at (-2,-1.5) {kone $2$};
\draw[|-|] (0.05,-1.5) -- (2.95,-1.5);
\draw[|-|] (3.05,-1.5) -- (5.95,-1.5);
\node at (-2,-3) {kone $3$};
\draw[|-|] (0.05,-3) -- (6.95,-3);
\end{tikzpicture}
\caption{Optimaalinen tapa valmistaa 7 tavaraa vie 8 minuuttia,
kun koneiden nopeudet ovat $[2,3,7]$.}
\label{fig:optkon}
\end{figure}

Mutta mitä hyötyä on siitä, että löydämme tehokkaasti funktion muutoskohdan?
Tämä selviää seuraavassa tehtävässä:
Käytössämme on $n$ konetta
ja haluamme valmistaa niiden avulla $m$ tavaraa.
Tiedämme jokaisesta koneesta,
montako minuuttia kestää valmistaa yksi tavara konetta käyttäen,
ja haluamme löytää aikataulun, jota seuraamalla pystymme valmistamaan
$m$ tavaraa mahdollisimman nopeasti.

Kuva \ref{fig:optkon} näyttää parhaan aikataulun tilanteessa,
jossa koneiden nopeudet ovat $[2,3,7]$ ja haluamme
valmistaa seitsemän tavaraa (eli $m=7$).
Käynnistämme koneen 1 neljästi kahden minuutin välein,
koneen 2 kahdesti kolmen minuutin välein ja koneen 3 kerran.
Viimeisenä pysähtyy kone 1, kun aloittamisesta
on kulunut kahdeksan minuuttia.

Voimme pukea tehtävän binäärihaulle sopivaan muotoon määrittämällä,
että $\texttt{ok}(x)=\texttt{true}$ tarkalleen silloin, kun voimme muodostaa
\emph{ainakin} $m$ tavaraa ajassa $x$.
Tällöin funktion muutoskohta $k$ vastaa tehtävän ratkaisua.
Entä miten voimme laskea funktion \texttt{ok} arvon?
Jos meillä on $u$ minuuttia aikaa ja koneella $i$ kestää $x_i$
minuuttia valmistaa yksi tavara, pystymme valmistamaan
$\lfloor u/x_i \rfloor$ tavaraa kyseistä konetta käyttäen.
Kun sitten käytössämme on kaikki koneet,
pystymme valmistamaan yhteensä
\[ s = \sum_{i=1}^n \lfloor u/x_i \rfloor \]
tavaraa. Niinpä $\texttt{ok}(u)=\texttt{false}$, jos $s<m$,
ja $\texttt{ok}(u)=\texttt{true}$, jos $s \ge m$. Voimme toteuttaa tämän seuraavasti:

\begin{code}
ok(u)
    s = 0
    for i = 1 to n
        s += u/x[i]
    return s >= m
\end{code}

Voimme kytkeä tämän funktion suoraan binäärihakuun,
jolloin tuloksena on tehokas algoritmi tehtävän ratkaisemiseen.
Meidän täytyy kuitenkin vielä valita arvo $N$,
joka on jokin yläraja kohdalle $k$.
Tässä tehtävässä helppo valinta on
\[N = x_1 \cdot m,\]
mikä vastaa ratkaisua, jossa käytämme vain ensimmäistä konetta.
On varmaa, että oikea $k$:n arvo on korkeintaan $N$,
joten binäärihaku kutsuu $O(\log N)$ kertaa metodia $\texttt{ok}$.
Koska jokainen metodin kutsu vie aikaa $O(n)$,
tuloksena on algoritmi, jonka aikavaativuus on $O(n \log N)$.

Huomaa, että $\log N$ on käytännössä pieni luku riippumatta
siitä, kuinka suuri luku $N$ on.
Niinpä meidän ei tarvitse murehtia siitä,
kuinka suuria $x_1$ ja $m$ ovat,
vaan voimme luottaa siihen, että algoritmi on tehokas.

\subsection{Tasoitettu analyysi}

Voimme yleensä määrittää algoritmin aikavaativuuden
helposti katsomalla jokaisesta silmukasta,
montako kertaa siinä olevaa koodia suoritetaan.
Joskus näin suoraviivainen analyysi ei anna kuitenkaan
oikeaa kuvaa algoritmin tehokkuudesta,
koska silmukan suorituskertojen määrä saattaa vaihdella
algoritmin eri vaiheissa.
Tutustumme seuraavaksi tekniikkaan nimeltä
\emph{tasoitettu analyysi}, jossa koetamme arvioida tarkemmin,
montako kertaa silmukassa olevaa koodia suoritetaan
\emph{yhteensä} algoritmin aikana.

Tasoitettuun analyysiin liittyy yleensä jokin tietorakenne,
jonka operaatioiden määrää haluamme arvioida.
Tarkastellaan esimerkkinä tehtävää,
jossa meillä on $n$ lukua sisältävä taulukko
ja haluamme muodostaa toisen taulukon,
jossa on jokaisen luvun \emph{lähin pienempi edeltäjä}.
Tämä tarkoittaa, että haluamme löytää jokaiselle luvulle
pienemmän luvun, joka on mahdollisimman lähellä aiemmin taulukossa.
Esimerkiksi taulukon $[1,4,5,2,3,2]$
lähimmät pienemmät edeltäjät ovat $[-,1,4,1,2,1]$.
Koska luvulla $1$ ei ole pienempää edeltäjää,
sen kohdalla on merkki $-$.

Seuraava koodi ratkaisee tehtävän $O(n^2)$-ajassa ja muodostaa
taulukon \texttt{edeltaja}, jossa on jokaisen luvun lähin pienempi edeltäjä:

\begin{code}
for i = 0 to n-1
    for j = i-1 to 0
        if taulu[j] < taulu[i]
            edeltaja[i] = taulu[j]
            break
\end{code}

Saamme aikaan tehokkaan ratkaisun käymällä läpi taulukon
vasemmalta oikealle ja pitämällä yllä \emph{pinoa}, jossa on
kasvava lista taulukon lukuja.
Jokaisessa kohdassa $i$ poistamme ensin pinon lopusta lukuja
niin kauan kuin pinon viimeinen luku on suurempi tai yhtä
suuri kuin kohdan $i$ luku.
Tämän jälkeen kirjaamme muistiin, että kohdan $i$ luvun
lähin pienempi edeltäjä on pinon viimeinen luku (jos pino ei ole tyhjä) ja
lisäämme kohdan $i$ luvun pinon loppuun.
Tuloksena on seuraava algoritmi:

\begin{code}
pino = []
for i = 0 to n-1
    while not pino.empty() and pino.top() >= taulu[i]
        pino.pop()
    if not pino.empty()
        edeltaja[i] = pino.top()
    pino.push(taulu[i])
\end{code}

\begin{figure}
\center
\begin{tikzpicture}[scale=0.6]
\newcommand\pino[3]{
\node[draw,rectangle,minimum size=12pt] (#1) at (#2+0.5,-0.75) {};
\node at (#2+0.5,-0.75) {#3};
}
\begin{scope}
\fill[color=lightgray] (0,0) rectangle (1,1);
\draw (0,0) grid (6,1);
\foreach \i/\x in {0/1,1/4,2/5,3/2,4/3,5/2} \node at (\i+0.5,0.5) {\x};
\pino{1}{0}{1}
\node at (3,-2) {vaihe $1$};
\end{scope}
\begin{scope}[xshift=10cm]
\fill[color=lightgray] (1,0) rectangle (2,1);
\draw (0,0) grid (6,1);
\foreach \i/\x in {0/1,1/4,2/5,3/2,4/3,5/2} \node at (\i+0.5,0.5) {\x};
\pino{1}{0}{1}
\pino{2}{1}{4}
\draw[thick,->] (1) -- (2);
\node at (3,-2) {vaihe $2$};
\end{scope}
\begin{scope}[yshift=-5cm]
\fill[color=lightgray] (2,0) rectangle (3,1);
\draw (0,0) grid (6,1);
\foreach \i/\x in {0/1,1/4,2/5,3/2,4/3,5/2} \node at (\i+0.5,0.5) {\x};
\pino{1}{0}{1}
\pino{2}{1}{4}
\pino{3}{2}{5}
\draw[thick,->] (1) -- (2);
\draw[thick,->] (2) -- (3);
\node at (3,-2) {vaihe $3$};
\end{scope}
\begin{scope}[yshift=-5cm,xshift=10cm]
\fill[color=lightgray] (3,0) rectangle (4,1);
\draw (0,0) grid (6,1);
\foreach \i/\x in {0/1,1/4,2/5,3/2,4/3,5/2} \node at (\i+0.5,0.5) {\x};
\pino{1}{0}{1}
\pino{2}{3}{2}
\draw[thick,->] (1) -- (2);
\node at (3,-2) {vaihe $4$};
\end{scope}
\begin{scope}[yshift=-10cm]
\fill[color=lightgray] (4,0) rectangle (5,1);
\draw (0,0) grid (6,1);
\foreach \i/\x in {0/1,1/4,2/5,3/2,4/3,5/2} \node at (\i+0.5,0.5) {\x};
\pino{1}{0}{1}
\pino{2}{3}{2}
\pino{3}{4}{3}
\draw[thick,->] (1) -- (2);
\draw[thick,->] (2) -- (3);
\node at (3,-2) {vaihe $5$};
\end{scope}
\begin{scope}[yshift=-10cm,xshift=10cm]
\fill[color=lightgray] (5,0) rectangle (6,1);
\draw (0,0) grid (6,1);
\foreach \i/\x in {0/1,1/4,2/5,3/2,4/3,5/2} \node at (\i+0.5,0.5) {\x};
\pino{1}{0}{1}
\pino{2}{5}{2}
\draw[thick,->] (1) -- (2);
\node at (3,-2) {vaihe $6$};
\end{scope}
\end{tikzpicture}
\caption{Etsimme lähimmät pienemmät edeltäjät pinon avulla.}
\label{fig:pielah}
\end{figure}

Kuva \ref{fig:pielah} näyttää, kuinka algoritmi käsittelee taulukon $[1,4,5,2,3,2]$.
Alussa pino on tyhjä, joten toteamme, ettei luvulla 1
ole lähintä pienintä edeltäjää ja lisäämme sen pinoon.
Sitten vuoroon tulee luku 4, jonka lähin pienin edeltäjä
on pinon päällä oleva luku 1. Tämän jälkeen lisäämme luvun 4 pinoon.
Vastaavasti luvun 5 lähin pienin edeltäjä on luku 4,
ja lisäämme luvun 5 pinoon.
Luvun 2 kohdalla poistamme pinosta luvut 5 ja 4
ja toteamme, että luvun 2 lähin pienin edeltäjä on luku 1.
Lopuksi käsittelemme vielä vastaavasti luvut 3 ja 2.

Algoritmin tehokkuus riippuu siitä, montako kertaa suoritamme
\texttt{while}-silmukassa olevan koodin.
Oleellinen havainto on, että voimme poistaa pinosta
korkeintaan niin monta alkiota kuin olemme lisänneet siihen,
eli emme voi kutsua \texttt{pop}-metodia useammin kuin \texttt{push}-metodia.
Koska lisäämme pinoon $n$ alkiota, suoritamme \texttt{while}-silmukassa
olevaa koodia siis enintään $n$ kertaa algoritmin aikana.
Tämän ansiosta koko algoritmi vie aikaa vain $O(n)$.