\chapter{Algoritmien suunnittelu}

Kuinka voi suunnitella hyvän algoritmin?
On selvää, ettei tähän kysymykseen ole yhtä helppoa vastausta.
Yhtä hyvin voisi kysyä, kuinka voi kirjoittaa hyvän kirjan
tai säveltää hyvää musiikkia.
Algoritmien suunnittelu on taito, jonka oppiminen vie aikaa.

Hyvä tavoite algoritmien suunnittelussa on saada aikaan
algoritmi, joka toimii ajassa $O(n)$ tai $O(n \log n)$.
Tällaisen algoritmin etuna on, että se toimii tehokkaasti
myös silloin, kun syötteen koko $n$ on suuri.
Tavoitteen asettaminen etukäteen on hyödyllistä,
koska kun tiedämme tavoitteen, voimme ottaa sen suunnittelumme
lähtökohdaksi ja rajata sen avulla mahdollisia
lähestymistapoja, joita voimme käyttää.

\section{Algoritmin tehostaminen}

Millainen on algoritmi, joka vie aikaa $O(n)$ tai $O(n \log n)$?
Tämä tarkoittaa,
että kun algoritmille annetaan syötteenä $n$ alkiota,
se saa käyttää jokaisen alkion käsittelyyn
vain pienen määrän aikaa.
Niinpä algoritmissa tulisi esiintyä seuraavan kaltaisia silmukoita:

\begin{code}
for i = 0 to n-1
    // tee jotain nopeaa
\end{code}

Tässä ''jotain nopeaa'' tarkoittaa koodia, joka vie aikaa
$O(1)$ tai $O(\log n)$.
Algoritmi voi myös järjestää aineistoa,
koska tehokkaat järjestämisalgoritmit vievät aikaa $O(n \log n)$.
Kovin paljon muuta tehokas algoritmi ei sitten voikaan tehdä.
Tämä rajoittaa paljon, mitä aineksia voimme laittaa algoritmiin,
mutta voimme ajatella asiaa myös myönteisesti:
vaatimus tehokkuudesta rajaa pois suuren määrän lähestymistapoja,
eli meidän on helpompaa löytää hyvä algoritmi,
kun vaihtoehtojen määrä on pienempi.

Tavallinen tilanne algoritmien suunnittelussa on,
että pystymme ratkaisemaan annetun ongelman
helposti $O(n^2)$-ajassa ensimmäisellä mieleen tulevalla algoritmilla,
mutta tarvitsisimme tehokkaamman algoritmin,
joka toimisi ajassa $O(n)$ tai $O(n \log n)$.
Kokemus on osoittanut, että tämä on hyvä tilanne:
yleensä \emph{pystymme} tehostamaan
tavalla tai toisella algoritmia,
kunhan mietimme huolellisesti asiaa.
Donald Knuth kuvailee samaa ilmiötä teoksessaan
\emph{The Art of Computer Programming} (osa 4A, esipuhe):

\begin{quote}
Starting about 1970, computer scientists began to experience
a phenomenon that we called ''Floyd's Lemma'':
Problems that seemed to need $n^3$ operations could actually be
solved in $O(n^2)$; problems that seemed to require $n^2$
could be handled in $O(n \log n)$; and $n \log n$ was often
reducible to $O(n)$.
\end{quote}

Tarkastellaan esimerkkinä seuraavaa tehtävää:
Annettuna on taulukko, joka sisältää luvut $1,2,\dots,n$
jossakin järjestyksessä,
ja haluamme kerätä taulukon luvut järjestyksessä pienimmästä suurimpaan.
Joka kierroksella käym\-me läpi taulukon vasemmalta
oikealle ja keräämme mahdollisimman monta seuraavaa lukua.
Montako kierrosta tarvitsemme yhteensä?
Esimerkiksi taulukossa $[4,3,1,5,2]$
tarvitsemme kolme kierrosta:
ensimmäisellä kierroksella keräämme luvut $1$ ja $2$,
toisella luvun $3$ ja kolmannella luvut $4$ ja $5$.

Voimme ratkaista tehtävän helposti $O(n^2)$-ajassa
simuloimalla lukujen keräämistä tehtävänannon kuvaamalla tavalla:

\begin{code}
luku = 1
laskuri = 0
while luku <= n
    laskuri++
    for i = 0 to n-1
        if taulu[i] == luku
            luku++
print(laskuri)
\end{code}

Tässä muuttuja \texttt{luku} kertoo,
minkä luvun haluamme kerätä seuraavaksi,
ja muuttuja \texttt{laskuri} laskee,
montako kierrosta tarvitaan.
Kierroksia tarvitaan aina korkeintaan $n$,
koska saamme kerättyä joka kierroksella
ainakin yhden luvun,
joten algoritmi toimii ajassa $O(n^2)$.

Kuinka voisimme sitten tehostaa algoritmia niin,
että se veisi aikaa vain $O(n)$ tai $O(n \log n)$?
Yllä olevan algoritmin hitaus johtuu pohjimmiltaan siitä,
että algoritmilla menee kauan aikaa löytää,
missä kohdassa taulukossa on seuraava luku,
jonka haluamme kerätä.
Niinpä jotta voimme ratkaista tehtävän tehokkaasti,
meidän täytyy jollakin tavalla löytää seuraava kerät\-tävä luku nopeammin.
Kätevä ratkaisu tähän on luoda aputaulukko \texttt{kohta},
joka kertoo jokaisen luvun kohdan:

\begin{code}
for i = 0 to n-1
    kohta[taulu[i]] = i
\end{code}

Tämän taulukon avulla saamme selville $O(1)$-ajassa,
missä kohdassa taulukossa on seuraava kerättävä luku.
Entä mistä tiedämme, montako kierrosta tarvitsemme?
Meidän täytyy aloittaa uusi kierros aina silloin,
kun viimeksi keräämämme luku on myöhemmin taulukossa
kuin seuraava kerättävä luku.
Niinpä voimme laskea kierrosten määrän näin:

\begin{code}
laskuri = 1
for i = 2 to n
    if kohta[i-1] > kohta[i]
        laskuri++
print(laskuri)
\end{code}

Tuloksena on algoritmi, jossa on kaksi silmukkaa,
joista molemmat vievät aikaa vain $O(n)$.
Niinpä algoritmin aikavaativuus on $O(n)$,
eli olemme saavuttaneet tavoitteemme.

\section{Algoritmien aineksia}

Seuraavaksi käymme läpi tarkemmin \emph{aineksia},
joita näkee usein tehokkaissa algoritmeissa.
Nämä ainekset muodostavat hyvän perustan algoritmien
suunnitteluun: kun saamme vastaamme uuden ongelman,
voimme miettiä, voisimmeko hyödyntää aineksia jotenkin
ongelman ratkaisemisessa.

\subsection{Järjestäminen}

Tehokas algoritmi perustuu usein tavalla tai toisella järjestämiseen.
Monessa tilanteessa meidän on helpompaa lähestyä ongelmaa,
jos voimme olettaa, että syöte on järjestyksessä.
Järjestäminen vie aikaa $O(n \log n)$, joten voimme käyttää sitä
huoletta tehokkaassa algoritmissa.

Jotta voimme käyttää järjestämistä, meidän täytyy usein havaita
ongelmasta jokin ominaisuus, jonka ansiosta voimme ratkaista
ongelman \emph{ahneella} algoritmilla.
Tyypillinen ahne algoritmi käy syötteen läpi järjestyksessä ja
muodostaa ratkaisun suoraan tämän järjestyksen perusteella.
Meidän täytyy kuitenkin olla varmoja, että saamme oikean ratkaisun tällä tavalla.

Tarkastellaan esimerkkinä tehtävää, jossa haluamme laskea
tutkijan \emph{$h$-indeksin}. Tämä on suurin luku $x$, jolle pätee,
että tutkijalla on $x$ julkaisua, joihin on viitattu ainakin $x$ kertaa.
Esimerkiksi jos tutkijalla on kolme julkaisua,
joiden viittausmäärät ovat $[5,1,3]$, hänen $h$-indeksinsä on $2$,
koska hänellä on kaksi julkaisua, joihin on viitattu ainakin kahdesti.

Tässä tehtävässä hyödyllinen havainto on, että meidän kannattaa aina
tarkastella tutkijan \emph{viitatuimpia} julkaisuja.
Jos tutkijan $h$-indeksi on $x$, voimme tarkastella vain $x$ viitatuinta
julkaisua, ja kaikissa niissä viittausmäärän on oltava ainakin $x$.
Tämä havainto johtaa ahneeseen algoritmiin: järjestämme ensin
viittausmäärät ja etsimme sitten suurimman arvon $x$,
jolle pätee, että $x$ viitatuimman julkaisun joukossa vähiten viitatussa
julkaisussa on ainakin $x$ viittausta. Voimme toteuttaa algoritmin seuraavasti:

\begin{code}
sort(viittaukset)
h_indeksi = 0
for x = 1 to n
    if viittaukset[n-x] >= x
        h_indeksi = x
\end{code}

Taulukon järjestäminen vie aikaa $O(n \log n)$ ja for-silmukka vie aikaa $O(n)$,
joten algoritmi toimii ajassa $O(n \log n)$.

\subsection{Tietorakenteet}

Olemme tutustuneet kirjassa moniin tietorakenteisiin:
listoihin, hajautustauluun, binäärihakupuuhun ja kekoon.
Näissä tietorakenteissa kannattaa kiinnittää erityisesti huomiota siihen,
mitkä operaatiot toimivat tehokkaasti $O(1)$- tai $O(\log n)$-ajassa.
Nämä ovat operaatioita, joita voimme käyttää tehokkaissa algoritmeissa.

Tarkastellaan esimerkkinä tehtävää, jossa haluamme laskea,
monellako tavalla voimme valita $n$ luvun taulukosta yhtenäisen osataulukon,
jossa lukujen summa on $x$.
Voimme ratkaista tehtävän suoraviivaisesti kahdella for-silmukalla
ajassa $O(n^2)$ käymällä läpi kaikki osataulukot:

\begin{code}
laskuri = 0
for i = 0 to n-1
    summa = 0
    for j = i to n-1
        summa += taulu[j]
        if summa == x:
            laskuri++
\end{code}

Entä kuinka voisimme ratkaista tehtävän tehokkaasti?
Tässä auttaa muotoilla hieman toisin, mitä tarkoittaa,
että osataulukon summa on $x$.
Merkitään $s(i)$:llä osataulukon summaa taulukon alusta
kohtaan $i$ asti, ja oletetaan lisäksi, että $s(-1)=0$.
Tätä merkintää käyttäen osataulukon summa
kohdasta $a$ kohtaan $b$ on
\[s(b)-s(a-1),\]
eli meidän riittää oikeastaan keskittyä vain taulukon alusta
alkavien osataulukoiden summiin.

Koska haluamme saada tehokkaan algoritmin,
hyvä tavoite olisi käydä taulukko läpi vain kerran.
Kun olemme taulukon kohdassa $i$,
monessako tähän kohtaan päättyvässä osataulukossa
lukujen summa on $x$?
Tämä tarkoittaa, että haluamme etsiä kohdat $j<i$,
joille pätee
\[s(i)-s(j-1)=x\]
eli
\[s(j-1)=s(i)-x.\]
Tämä onnistuu tehokkaasti, kun pidämme taulukon läpikäynnissä
kirjaa, montako kertaa mikäkin summa on esiintynyt taulukon alkuosassa.
Voimme toteuttaa algoritmin seuraavasti:

\begin{code}
summat[0] = 1
laskuri = 0
summa = 0
for i = 0 to n-1
    laskuri += summat[taulu[i]-x]
    summa += taulu[i]
    summat[summa]++
\end{code}

Tässä rakenne \texttt{summat} pitää kirjaa,
montako kertaa mikäkin alkuosan summa on esiintynyt tähän mennessä.
Koska summat voivat olla suuria, emme voi käyttää tavallista taulukkoa,
mutta voimme sen sijaan käyttää hajautustaulua tai binäärihakupuuta
(Javassa rakenteet \texttt{HashMap} ja \texttt{TreeMap}).
Näin saamme aikaan ratkaisun, joka vie aikaa $O(n)$ tai $O(n \log n)$
riippuen valitusta tietorakenteesta.

\subsection{Binäärihaku}

Binäärihaun tunnetuin käyttötarkoitus on alkion etsiminen
järjestetystä taulukosta ajassa $O(\log n)$.
Tämä on kuitenkin vain alkusoittoa sille,
mitä binää\-rihaulla pystyy tekemään ja mikä on sen
merkitys algoritmiikassa.

Oletetaan, että meillä on funktio $\texttt{ok}(x)$,
joka kertoo, onko $x$ kelvollinen ratkaisu tehtävään.
Lisäksi pätee $\texttt{ok}(x)=\texttt{false}$, kun $x<k$,
ja $\texttt{ok}(x)=\texttt{true}$, kun $x \ge k$.
Binäärihaun avulla voimme etsiä tehokkaasti,
mikä on funktion \emph{muutoskohta} $k$
eli ensimmäinen kohta, jossa funktio saa arvon \texttt{true}.
Seuraava koodi toteuttaa haun,
kun $k$ on välillä $1 \dots N$:


\begin{code}
a = 1
b = N
while a < b
    u = (a+b)/2
    if ok(u)
        b = u
    else
        a = u+1
k = a
\end{code}

Haun joka vaiheessa tiedämme, että muutoskohta on välillä $[a,b]$.
Laskemme keskikohdan $u=(a+b)/2$ ja tutkimme funktion arvoa kohdassa $u$.
Jos pätee $\texttt{ok}(u)$, niin muutoskohdan on oltava välillä $[a,u]$,
ja muuten sen täytyy olla välillä $[u+1,b]$.
Lopulta välillä on vain yksi alkio, jolloin olemme löytäneet muutoskohdan.
Koska välin koko puolittuu joka askeleella,
kutsumme $O(\log N)$ kertaa funktiota $\texttt{ok}$.

Mutta mitä hyötyä on siitä, että löydämme tehokkaasti funktion muutoskohdan?
Tämä selviää seuraavissa esimerkkitehtävissä.

\subsection{Esimerkki: Tehdas}

Käytössämme on $n$ konetta
ja haluamme valmistaa niiden avulla $m$ tavaraa.
Tiedossamme on arvot $x_1,x_2,\dots,x_n$:
jokaisesta koneesta tieto, kuinka paljon aikaa vie valmistaa
yksi tavara konetta käyttäen.
Haluamme löytää aikataulun, jota seuraamalla pystymme valmistamaan
vaaditut $m$ tavaraa mahdollisimman nopeasti.

Esimerkiksi jos $n=3$, $m=7$ ja koneiden nopeudet ovat $[2,3,7]$,
paras aikataulu on kuvassa \ref{fig:optkon}.
Sitä käyttäen tavaroiden muodostaminen vie aikaa $8$ minuuttia.
Käynnistämme koneen 1 neljästi hetkinä 0, 2, 4 ja 6,
koneen 2 kahdesti hetkinä 0 ja 3
ja koneen 3 kerran hetkenä 0.
Aikaa kuluu $8$ minuuttia, koska viimeisenä pysähtyy kone 1 hetkenä 8.

\begin{figure}
\center
\begin{tikzpicture}[scale=0.7]
\draw[->] (-1,1.5) -- (10,1.5);
\foreach \x in {0,...,8} \draw (\x,1.40) -- (\x,1.60);
\foreach \x in {0,...,8} \node at (\x,2) {\scriptsize $\x$};
\node at (-2,0) {kone $1$};
\draw[|-|] (0.05,0) -- (1.95,0);
\draw[|-|] (2.05,0) -- (3.95,0);
\draw[|-|] (4.05,0) -- (5.95,0);
\draw[|-|] (6.05,0) -- (7.95,0);
\node at (-2,-1.5) {kone $2$};
\draw[|-|] (0.05,-1.5) -- (2.95,-1.5);
\draw[|-|] (3.05,-1.5) -- (5.95,-1.5);
\node at (-2,-3) {kone $3$};
\draw[|-|] (0.05,-3) -- (6.95,-3);
\end{tikzpicture}
\caption{Optimaalinen tapa valmistaa 7 tavaraa vie 8 sekuntia,
kun koneiden nopeudet ovat $[2,3,7]$.}
\label{fig:optkon}
\end{figure}

Voimme pukea tehtävän binäärihaulle sopivaan muotoon niin,
että $f(x)=1$ tarkalleen silloin, kun voimme muodostaa
\emph{ainakin} $m$ tavaraa ajassa $x$.
Tällöin funktion muutoskohta $k$ vastaa tehtävän ratkaisua.
Entä miten voimme laskea funktion $f$ arvon?
Jos meillä on $u$ minuuttia aikaa ja jollakin koneella kestää $x_i$
minuuttia valmistaa yksi tavara, pystymme valmistamaan
$\lfloor u/x_i \rfloor$ tavaraa kyseistä konetta käyttäen.
Kun sitten käytössämme on kaikki koneet,
pystymme valmistamaan yhteensä
\[ s = \sum_{i=1}^n \lfloor u/x_i \rfloor \]
tavaraa. Niinpä $f(u)=0$, jos $s<m$,
ja $f(u)=1$, jos $s \ge m$. Voimme toteuttaa tämän seuraavasti:

\begin{code}
int f(int u) {
    int s = 0;
    for (int i = 1; i <= n; i++) s += u/x[i];
    return (s < m) ? 0 : 1;
}
\end{code}

Voimme kytkeä tämän metodin suoraan binäärihakuun,
jolloin tuloksena on tehokas algoritmi tehtävän ratkaisemiseen.
Meidän täytyy kuitenkin vielä valita arvo $N$,
joka on jokin yläraja kohdalle $k$.
Tässä tehtävässä helppo valinta on
\[N = x_1 \cdot m,\]
mikä vastaa ratkaisua, jossa käytämme vain ensimmäistä konetta.
On varmaa, että oikea $k$:n arvo on korkeintaan $N$,
joten binäärihaku kutsuu $O(\log N)$ kertaa metodia $\texttt{f}$.
Koska jokainen metodin kutsu vie aikaa $O(n)$,
tuloksena on algoritmi, jonka aikavaativuus on $O(n \log N)$.

Huomaa, että $\log N$ on käytännössä pieni luku riippumatta
siitä, kuinka suuri luku $N$ on.
Niinpä meidän ei tarvitse murehtia siitä,
kuinka suuria $x_1$ ja $m$ ovat,
vaan voimme luottaa siihen, että algoritmi on tehokas.

\subsection{Tasoitettu analyysi}

Tähän mennessä olemme arvioineet algoritmien tehokkuutta
lähinnä määrit\-tämällä jokaiselle silmukalle ylärajan,
montako kertaa siinä olevaa koodia suoritetaan.
Tämä onkin yleensä hyvä tapa laskea aikavaativuus,
mutta joskus ongelmaksi voi tulla, että silmukan kierrosten
määrä vaihtelee algoritmin eri vaiheissa eikä yläraja
anna oikeaa kuvaa tehokkuudesta.

Seuraavaksi tutustumme tekniikkaan nimeltä
\emph{tasoitettu analyysi}, jossa koetamme arvioida tarkemmin,
montako kertaa silmukassa olevaa koodia suoritetaan
\emph{yhteensä} algoritmin aikana.
Tämän avulla pystymme joskus huomaamaan, että algoritmi
toimii tehokkaammin kuin vaikuttaa ensin.

\subsection{Alitaulukot, osa 2}

Palaamme aluksi tehtävään, jossa meille on annettu
$n$ positiivisen kokonaisluvun taulukko ja haluamme laskea,
monenko yhtenäisen alitaulukon summa on $x$.
Olemme jo ratkaisseet tehtävän ajassa $O(n \log n)$
binäärihaun ja summataulukon avulla,
mutta nyt ratkaisemme tehtävän vielä tehokkaammin
ajassa $O(n)$ esimerkkinä tasoitetusta analyysista.

Ideana on, että meillä on kaksi muuttujaa $i$ ja $j$,
jotka osoittavat taulukkoon.
Muuttujat aloittavat taulukon alusta,
ja jokaisella vuorolla $i$ siirtyy askeleen oikealle
ja $j$ siirtyy oikealle niin kauan, kunnes välin $[i,j]$
lukujen summa on ainakin $x$.
Jos lukujen summa on tasan $x$, olemme löytäneet yhden
alitaulukon, jonka summa on $x$.
Seuraava koodi toteuttaa algoritmin:

\begin{code}
int j = -1;
int summa = 0;
int laskuri = 0;
for (int i = 0; i < n; i++) {
    while (j+1 < n && summa < x) {
        j++;
        summa += taulu[j];
    }
    if (summa == x) laskuri++;
    summa -= taulu[i];
}
System.out.println(laskuri);
\end{code}

Tästä koodista on ensin näkemältä vaikeaa määrittää algoritmin
aikavaativuutta, koska ei ole varmaa, montako kierrosta
\texttt{while}-silmukkaa suoritetaan milloinkin.
Saattaa olla, että jollakin kertaa silmukkaa ei suoriteta lainkaan
mutta toisella kertaa $O(n)$ kierrosta.
Koska silmukkaa suoritetaan aina enintään $O(n)$ kierrosta,
saamme algoritmille aikavaativuuden $O(n^2)$,
mutta antaako tämä hyvän kuvan algoritmista?

Voimme analysoida algoritmia tarkemmin kiinnittämällä huomiota
siihen, miten muuttujan $j$ arvo muuttuu algoritmissa.
Muuttujan arvo on aluksi $-1$,
se kasvaa yhdellä jokaisella \texttt{while}-silmukan kierroksella
ja silmukkaan mennään vain, jos arvo on enintään $n-1$.
Niinpä voimme päätellä, että silmukassa oleva koodi suoritetaan \emph{yhteensä}
$O(n)$ kertaa, mikä tarkoittaa sitä,
että koko algoritmin aikavaativuus on vain $O(n)$.

\subsection{Lähin pienempi edeltäjä}

Tasoitettuun analyysiin liittyy usein jokin tietorakenne,
jonka operaatioiden määrää haluamme arvioida.
Näin on myös seuraavassa tehtävässä:

Annettuna on taulukko, jossa on $n$ kokonaislukua,
ja haluamme muodostaa toisen taulukon,
jossa on jokaisen luvun \emph{lähin pienempi edeltäjä}.
Tämä tarkoittaa, että haluamme löytää jokaiselle taulukon luvulle
sitä pienemmän luvun, joka on mahdollisimman lähellä aiemmin taulukossa.
Esimerkiksi taulukon $[1,4,5,2,3,2]$
lähimmät pienemmät edeltäjät ovat $[-,1,4,1,2,1]$.
Koska luvulla $1$ ei ole pienempää edeltäjää,
sen kohdalla on merkki $-$.

Seuraavassa on $O(n^2)$-algoritmi, joka etsii
lähimmät pienemmät edeltäjät:

\begin{code}
for (int i = 0; i < n; i++) {
    for (int j = i-1; j >= 0; j--) {
        if (taulu[j] < taulu[i]) {
            edeltaja[i] = taulu[j];
            break;
        }
    }
}
\end{code}

Ratkaisemme tehtävän tehokkaasti pitämällä yllä \emph{pinoa},
jossa on kasvava lista taulukon lukuja.
Pino on tietorakenne, jossa voimme lisätä alkion pinon päälle
ja hakea tai poistaa pinon ylimmän alkion.
Voisimme toteuttaa pinon listana,
mutta Javassa on myös erikoistunut tietorakenne \texttt{Stack},
jota käytämme seuraavassa koodissa:

\begin{code}
Stack<Integer> pino = new Stack<>();
for (int i = 0; i < n; i++) {
    while (!pino.empty() && pino.peek() >= taulu[i]) {
        pino.pop();
    }
    if (!pino.empty()) {
        edeltaja[i] = pino.peek();
    }
    pino.push(taulu[i]);
}
\end{code}

Metodi \texttt{push} lisää alkion pinoon,
\texttt{peek} hakee ylimmän alkion ja \texttt{pop}
poistaa ylimmän alkion.
Ideana on, että säilytämme pinossa kasvavassa järjestyk\-sessä
ehdokkaita tulevien lukujen lähimmiksi pienimmiksi edeltäjiksi.
Jokaisessa taulukon kohdassa poistamme
pinosta lukuja, kunnes pinon ylin luku on pienempi kuin nykyinen luku
tai pino on tyhjä.
Jos pino ei ole tämän jälkeen tyhjä, sen ylin luku on nykyisen luvun
lähin pienempi edeltäjä.
Lopuksi lisäämme nykyisen luvun pinoon päälle.

Algoritmin tehokkuus riippuu siitä, montako kertaa suoritamme
\texttt{while}-silmukassa olevan koodin.
Oleellinen havainto on, että voimme poistaa pinosta
korkeintaan niin monta alkiota kuin olemme lisänneet siihen,
eli emme voi kutsua \texttt{pop}-metodia useammin kuin \texttt{push}-metodia.
Koska lisäämme pinoon $n$ alkiota, suoritamme \texttt{while}-silmukkaa
siis enintään $n$ kierrosta.
Tämän ansiosta algoritmin aikavaativuus on $O(n)$.