\chapter{Tehokkuus}

Algoritmien suunnittelussa keskeinen tavoite on saada aikaan
algoritmeja, jotka toimivat \emph{tehokkaasti}.
Haluamme luoda algoritmeja, joiden avulla voimme
käsitellä myös suuria aineistoja ilman, että joudumme
odottamaan kauan.
Tässä luvussa tutustumme työkaluihin, joiden avulla
voimme arvioida algoritmien tehokkuutta.
Keskeinen käsite on aikavaativuus, joka antaa
tiiviissä muodossa kuvan algoritmin ajankäytöstä.

Algoritmien tehokkuudella on suuri merkitys käytännössä.
Esimerkiksi Google-haku on käyttökelpoinen sen vuoksi,
että saamme hakutulokset välittömästi hakusanan lähettämisen
jälkeen.
Jos joutuisimme odottamaan jokaisen tekemämme haun
tuloksia vaikkapa viikon,
tämä rajoittaisi paljon sitä, miten voisimme käyttää hakua.


\section{Aikavaativuus}

Algoritmin tehokkuus riippuu siitä,
montako askelta se suorittaa.
Tavoitteemme on nyt arvioida tehokkuutta suhteessa
syötteen kokoon $n$.
Esimerkiksi jos syötteenä on taulukko,
$n$ on taulukon koko,
ja jos syötteenä on merkkijono,
$n$ on merkkijonon pituus.

Tarkastellaan esimerkkinä seuraavaa algoritmia,
joka laskee, montako kertaa luku $x$ esiintyy
$n$ lukua sisältävässä taulukossa.

\begin{code}[numbers=left]
int maara = 0;
for (int i = 0; i < n; i++) {
    if (luvut[i] == x) {
        maara++;
    }
}
\end{code}

Tämän algoritmissa oleelliset askeleet ovat riveillä
1, 3 ja 4.
Rivi 1 suoritetaan vain kerran algoritmin alussa.
Rivn 3 suoritetaan $n$ kertaa jokaisella silmukan
kierroksella.
Rivi 4 taas suoritetaan $0 \dots n$
kertaa riippuen siitä, kuinka usein
luku $x$ esiintyy taulukossa.
Algoritmi suorittaa siis vähintään $n+1$ ja enintään $2n+1$
askelta.

Näin tarkka analyysi ei ole kuitenkaan yleensä tarpeen,
vaan meille riittää määrittää karkea ajankäytön yläraja.
Sanomme, että algoritmi toimii ajassa $O(f(n))$ eli sen
\emph{aikavaativuus} on $O(f(n))$, jos se suorittaa
enintään $c f(n)$ askelta aina silloin kun $n \ge n_0$,
missä $c$ ja $n_0$ ovat vakioita.
Esimerkiksi yllä oleva algoritmi toimii ajassa $O(n)$,
koska se suorittaa selkeästi enintään $3n$ askelta
kaikilla $n$:n arvoilla.

Aikavaativuuden mukavana puolena on, että voimme yleensä
päätellä aikavaativuuden helposti algoritmin
rakenteesta. Tutustumme seuraavaksi laskusääntöihin,
joiden avulla tämä on mahdollista.

\subsection{Laskusääntöjä}

Jos koodissa ei ole silmukoita vaan vain
yksittäisiä komentoja, sen aikavaativuus on $O(1)$.
Näin on esimerkiksi seuraavassa koodissa:

\begin{code}
c = (a+b)/2;
if (c < 0) c = -c;
\end{code}

Merkitsemme \texttt{...} koodia,
jonka aikavaativuus on $O(1)$.
Jos koodissa on yksi silmukka,
joka suorittaa $n$ askelta,
sen aikavaativuus on $O(n)$:

\begin{code}
for (int i = 0; i < n; i++) {
    ...
}
\end{code}

Jos tällaisia silmukoita on kaksi sisäkkäin,
aikavaativuus on $O(n^2)$:

\begin{code}
for (int i = 0; i < n; i++) {
    for (int j = 0; j < n; j++) {
        ...
    }
}
\end{code}

Yleisemmin jos koodissa on vastaavalla tavalla
$k$ sisäkkäistä silmukkaa, sen aikavaativuus on $O(n^k)$.

Huomaa, että vakiokertoimet ja matalammat termit eivät vaikuta aikavaativuuteen.
Esimerkiksi seuraavissa koodeissa silmukoissa on $2n$ ja $n-1$ askelta,
mutta kummankin koodin aikavaativuus on $O(n)$.

\begin{code}
for (int i = 0; i < 2*n; i++) {
    ...
}
\end{code}

\begin{code}
for (int i = 0; i < n-1; i++) {
    ...
}
\end{code}

Jos koodissa on peräkkäisiä osuuksia, kokonaisaikavaativuus on suurin
yksittäinen aikavaativuus. Esimerkiksi seuraavan koodin aikavaativuus on $O(n^2)$,
koska sen osuudet ovat $O(n)$, $O(n^2)$ ja $O(n)$.

\begin{code}
for (int i = 0; i < n; i++) {
    ...
}
for (int i = 0; i < n; i++) {
    for (int j = 0; j < n; j++) {
        ...
    }
}
for (int i = 0; i < n; i++) {
    ...
}
\end{code}

Joskus aikavaativuus riippuu useammasta tekijästä,
jolloin kaavassa on monta muuttujaa.
Seuraavan koodin aikavaativuus on $O(nm)$:

\begin{code}
for (int i = 0; i < n; i++) {
    for (int j = 0; j < m; j++) {
        ...
    }
}
\end{code}

\subsection{Yleisiä aikavaativuuksia}

Tietyt aikavaativuudet esiintyvät usein algoritmien analyysissa.
Seuraavaksi käymme läpi joukon tällaisia aikavaativuuksia.

\subsubsection{$O(1)$ (vakioaikainen)}

Vakioaikainen algoritmi suorittaa kiinteän määrän komentoja,
eikä syötteen suuruus vaikuta algoritmin nopeuteen.
Esimerkiksi seuraava algoritmi laskee summan $1+2+\dots+n$
vakioajassa summakaavan avulla:

\begin{code}
summa = n*(n+1)/2;
\end{code}

\subsubsection{$O(\log n)$ (logaritminen)}

Logaritminen algoritmi puolittaa usein syötteen koon
joka askeleella. Tyypillinen esimerkki logaritmisesta algoritmista
on binäärihaku, joka etsii alkiota järjestetystä taulukosta.

\begin{code}
int a = 0, b = n-1;
while (a <= b) {
    int k = (a+b)/2;
    if (taulu[k] == x) break;
    if (taulu[k] < x) a = k+1;
    else b = k-1;
}
\end{code}

\subsubsection{$O(n)$ (lineaarinen)}

Lineaarinen algoritmi voi käydä läpi syötteen kiinteän määrän kertoja.
Esimerkiksi seuraava algoritmi laskee taulukon lukujen summan $O(n)$-ajassa.

\begin{code}
int summa = 0;
for (int i = 0; i < n; i++) {
    summa += taulu[i];
}
\end{code}

\subsubsection{$O(n \log n)$ (järjestäminen)}

Aikavaativuus $O(n \log n)$ viittaa usein siihen,
että algoritmin osana on syöt\-teen järjestäminen,
koska tehokkaat järjestämisalgoritmit
toimivat ajassa $O(n \log n)$.
Esimerkiksi seuraava $O(n \log n)$-algoritmi laskee,
montako eri alkiota taulukko sisältää.

\begin{code}
Arrays.sort(taulu);
int maara = 1;
for (int i = 1; i < n; i++) {
    if (taulu[i] != taulu[i-1]) maara++;
}
\end{code}

\subsubsection{$O(n^2)$ (neliöllinen)}

Neliöllinen algoritmi voi käydä läpi kaikki tavat valita
kaksi alkiota syötteestä.
Esimerkiksi seuraava $O(n^2)$-algoritmi tutkii, onko taulukossa
kahta lukua, joiden summa on $x$.

\begin{code}
boolean ok = false;
for (int i = 0; i < n; i++) {
    for (int j = i+1; j < n; j++) {
        if (taulu[i]+taulu[j] == x) ok = true;
    }
}
\end{code}

\subsubsection{$O(n^3)$ (kuutiollinen)}

Kuutiollinen algoritmi voi käydä läpi kaikki tavat valita
kolme alkiota syötteestä.
Esimerkiksi seuraava $O(n^3)$-algoritmi tutkii, onko taulukossa
kolmea lukua, joiden summa on $x$.

\begin{code}
boolean ok = false;
for (int i = 0; i < n; i++) {
    for (int j = i+1; j < n; j++) {
        for (int k = j+1; k < n; k++) {
            if (taulu[i]+taulu[j]+taulu[k] == x) ok = true;
        }
    }
}
\end{code}

\subsubsection{$O(2^n)$ (osajoukot)}

Aikavaativuus $O(2^n)$ viittaa usein siihen,
että algoritmi käy läpi syötteen alkioiden osajoukot.
Esimerkiksi alkioiden $\{1,2,3\}$ osajoukot ovat
$\emptyset$, $\{1\}$, $\{2\}$, $\{3\}$, $\{1,2\}$, $\{1,3\}$, $\{2,3\}$ ja $\{1,2,3\}$.

\subsubsection{$O(n!)$ (permutaatiot)}

Aikavaativuus $O(n!)$ viittaa usein siihen,
että algoritmi käy läpi syötteen alkioiden permutaatiot.
Esimerkiksi alkioiden $\{1,2,3\}$ permutaatiot ovat
$(1,2,3)$, $(1,3,2)$, $(2,1,3)$, $(2,3,1)$, $(3,1,2)$ ja $(3,2,1)$.

\subsection{Tehokkuuden arviointi}

Mitä hyötyä on määrittää algoritmin aikavaativuus?
Hyötynä on, että aikavaativuus antaa meille pika-arvion siitä,
kuinka \emph{hyvä} algoritmi on eli miten suuria syötteitä
sillä voi käsitellä tehokkaasti.
Kun meille kertyy kokemusta algoritmien suunnittelusta,
meille alkaa muodostua selkeä kuva,
mitä eri aikavaativuudet tarkoittavat käytännössä.

Aikavaativuutta voi ajatella samalla tavalla kuin vaikkapa
hotellin tähti\-luokitusta: se kertoo tiiviissä muodossa,
mistä asiassa on kysymys, eikä mei\-dän tarvitse ottaa selvää yksityiskohdista.
Jos meille tarjoitaan majoitusta neljän tähden hotellissa,
saamme heti jonkin käsityksen huoneen tasosta,
vaikka meillä ei olisi listausta huoneen varustelusta.
Vastaavasti jos kuulemme, että jonkin algoritmin aikavaativuus on $O(n \log n)$,
voimme heti arvioida karkeasti, miten suuria syötteitä voimme käsitellä,
vaikka emme saisi tarkkaa kuvausta algoritmin toiminnasta.

\begin{table}
\center
\begin{tabular}{rrr}
aikavaativuus & syötteen koko \\
\hline
$O(n)$ ja $O(n \log n)$ & $10^6$ & \\
$O(n^2)$ & 5000 & \\
$O(n^3)$ & 500 & \\
$O(2^n)$ & 20 & \\
$O(n!)$ & 10 & \\
\end{tabular}
\caption{Kuinka suuren syötteen algoritmi voi käsitellä sekunnissa?}
\label{tab:algteh}
\end{table}

Yksi kiinnostava näkökulma algoritmin tehokkuuteen on,
miten suuren syötteen algoritmi voi käsitellä sekunnissa.
Taulukossa \ref{tab:algteh} on joitakin hyödyl\-lisiä arvioita
olettaen, että algoritmi suoritetaan tavallisella nykyaikaisella tietokoneella.
Esimerkiksi jos meillä on $O(n^2)$-algoritmi, voimme käsitellä sillä
tehokkaasti taulukon, jossa on luokkaa 5000 alkiota.
Jos tavoitteemme on käsitellä tehokkaasti suuria syötteitä,
meidän tulisi pyrkiä löytä\-mään $O(n)$- tai $O(n \log n)$-aikainen
algoritmi.

Kannattaa silti pitää mielessä, että nämä luvut ovat vain arvioita ja algoritmin
todelliseen ajankäyttöön vaikuttavat monet asiat.
Saman algoritmin hyvä toteutus saattaa olla
kymmenen kertaa nopeampi kuin huono toteutus,
vaikka aikavaativuudet olisivat samat.
Tässä kirjassa analysoimme algoritmeja sekä aikavaativuuksien
avulla että mittaamalla todellisia suoritusaikoja.

\section{Esimerkki: Bittijonot}

Seuraavaksi käymme läpi esimerkin, jossa vertailemme kahta
erilaista algoritmia samaan tehtävään.
Ensimmäinen algoritmi on suoraviivainen raa'an voiman
algoritmi, joka toimii ajassa $O(n^2)$.
Toinen algoritmi taas on tehokas algoritmi,
joka toimii ajassa $O(n)$.

Tehtävämme on seuraava: Annettuna on bittijono, jossa on $n$ bittiä,
ja haluamme laskea, monellako tavalla voimme valita kaksi kohtaa
niin, että vasen bitti on 0 ja oikea bitti on 1.
Esimerkiksi bittijonossa 01001 tapoja on neljä:
\underline{01}001, \underline{0}100\underline{1},
01\underline{0}0\underline{1} ja 010\underline{01}.

\subsubsection{$O(n^2)$-ratkaisu}

Suoraviivainen tapa ratkaista tehtävä on käydä läpi kaikki
mahdolliset tavat valita vasen ja oikea kohta ja laskea,
monessako tavassa vasen bitti on 0 ja oikea bitti on 1.
Seuraava metodi \texttt{laskeParit} toteuttaa tällaisen algoritmin.
Sille annetaan parametrina taulukko \texttt{bitit},
joka sisältää $n$ bittiä, ja metodi palauttaa vastauksena
tapojen määrän.

\begin{code}
public long laskeParit(int[] bitit) {
    int n = bitit.length;
    long tulos = 0;
    for (int i = 0; i < n; i++) {
        for (int j = i+1; j < n; j++) {
            if (bitit[i] == 0 && bitit[j] == 1) tulos++;
        }
    }
    return tulos;
}
\end{code}

Algoritmin aikavaativuus on $O(n^2)$, koska siinä on kaksi
sisäkkäistä silmukkaa, jotka käyvät läpi syötteen.

\subsubsection{$O(n)$-ratkaisu}

Kuinka voisimme ratkaista tehtävän tehokkaammin?
Meidän tulisi keksiä tapa, jolla saisimme
pois toisen silmukan koodista.

Tässä auttaa lähestyä ongelmaa hieman toisesta
näkökulmasta: kun olemme tietyssä kohdassa bittijonoa,
monellako tavalla voimme muodostaa parin,
jonka oikea bitti on nykyisessä kohdassamme?
Jos olemme bitin 0 kohdalla, pareja ei ole yhtään,
mutta jos bittinä on 1, voimme valita minkä tahansa
vasemmalla puolella olevan bitin 0 pariin.

Tämän havainnon ansiosta meidän riittää käydä läpi
bittijono kerran vasemmalta oikealle ja pitää kirjaa,
montako bittiä 0 olemme nähneet.
Sitten jokaisen bitin 1 kohdalla kasvatamme
vastausta tällä bittien 0 määrällä.
Seuraava koodi toteuttaa algoritmin:

\begin{code}
public long laskeParit(int[] bitit) {
    int n = bitit.length;
    long tulos = 0;
    int nollat = 0;
    for (int i = 0; i < n; i++) {
        if (bitit[i] == 0) nollat++;
        if (bitit[i] == 1) tulos += nollat;
    }
    return tulos;
}
\end{code}

Algoritmissa on vain yksi silmukka, joka käy syötteen läpi,
joten sen aikavaativuus on $O(n)$.

\subsubsection{Algoritmien vertailua}

Meillä on nyt siis kaksi algoritmia, joiden aikavaativuudet ovat
$O(n^2)$ ja $O(n)$, mutta mitä tämä tarkoittaa käytännössä?
Tämän selvittämiseksi voimme tehdä testin,
jossa mittaamme algoritmien suoritusaikoja
satunnaisilla syötteillä eri $n$:n arvoilla.

Taulukko \ref{tab:algver} näyttää tällaisen testin tulokset.
Pienillä $n$:n arvoilla molemmat algoritmit toimivat
hyvin tehokkaasti, mutta suuremmilla syötteillä on
nähtävissä huomattavia eroja.
Raakaan voimaan perustuva $O(n^2)$-algoritmi
alkaa hidastua selvästi testistä $n=10000$ alkaen,
ja testissä $n=1000000$ sillä kuluu jo lähes kolme minuuttia aikaa.
Tehokas $O(n)$-algoritmi taas selvittää suuretkin testit
salamannopeasti.

\begin{table}
\center
\begin{tabular}{rrr}
syötteen koko $n$ & $O(n^2)$-algoritmi & $O(n)$-algoritmi \\
\hline
$10$ & 0.00 s & 0.00 s\\
$100$ & 0.00 s & 0.00 s\\
$1000$ & 0.00 s & 0.00 s\\
$10000$ & 0.14 s & 0.00 s \\
$100000$ & 1.66 s & 0.00 s \\
$1000000$ & 172.52 s & 0.01 s \\
\end{tabular}
\caption{Algoritmien suoritusaikojen vertailu.}
\label{tab:algver}
\end{table}

Tämän kurssin keskeinen tavoitteemme on luoda algoritmeja,
jotka toimivat tehokkaasti myös silloin, kun niille annetaan suuria syötteitä.
Tämä tarkoittaa käytännössä sitä, että algoritmin aikavaativuuden tulisi
olla $O(n)$ tai $O(n \log n)$.
Jos algoritmin aikavaativuus on esimerkiksi $O(n^2)$,
se on auttamatta liian hidas suurien syötteiden käsittelyyn.

\section{Lisää algoritmien analysoinnista}

Aikavaativuuksissa käyttämämme $O$-merkintä on yksi monista merkinnöistä,
joiden avulla voimme arvioida funktioiden kasvunopeutta.
Tutustumme seuraavaksi tarkemmin näihin merkintöihin.

\subsection{Merkinnät $O$, $\Omega$ ja $\Theta$}

Algoritmien analysoinnissa usein esiintyviä merkintöjä ovat:

\begin{itemize}
\item \emph{Yläraja}: Funktio $g(n)$ on luokkaa $O(f(n))$, jos on olemassa vakiot $c$ ja $n_0$
niin, että $g(n) \le c f(n)$ aina kun $n \ge n_0$.
\item \emph{Alaraja}: Funktio $g(n)$ on luokkaa $\Omega(f(n))$, jos on olemassa vakiot $c$ ja $n_0$
niin, että $g(n) \ge c f(n)$ aina kun $n \ge n_0$.
\item \emph{Tarkka arvio}: Funktio $g(n)$ on luokkaa $\Theta(f(n))$, jos se on sekä luokkaa $O(f(n))$
että luokkaa $\Omega(f(n))$.
\end{itemize}

Vakion $c$ tarkoituksena on, että saamme arvion kasvunopeuden suuruusluokalle välittämättä
vakiokertoimista. Vakion $n_0$ tarkoituksena on, että keskitymme tarkastelemaan
kasvunopeutta suurilla $n$:n arvoilla.
Voimme myös kirjoittaa $g(n)=O(f(n))$, kun haluamme ilmaista,
että funktio $g(n)$ on luokkaa $O(f(n))$,
ja vastaavasti $\Omega$- ja $\Theta$-merkinnöissä.

Kun sanomme, että algoritmi toimii ajassa $O(f(n))$, tarkoitamme, että se suorittaa
\emph{pahimmassa tapauksessa} $O(f(n))$ askelta.
Tämä on yleensä hyvä tapa ilmoittaa algoritmin tehokkuus,
koska silloin annamme takuun siitä, että algoritmin ajankäytöllä on tietty yläraja,
vaikka syöte olisi valittu mahdollisimman ikävästi algoritmin kannalta.

Tarkastellaan esimerkkinä seuraavaa algoritmia, joka laskee
taulukon lukujen summan:

\begin{code}
int summa = 0;
for (int i = 0; i < n; i++) {
    summa += taulu[i];
}
\end{code}

Tämä algoritmi toimii samalla tavalla riippumatta taulukon sisällöstä,
koska se käy aina läpi koko taulukon.
Niinpä yläraja ajankäytölle on $O(n)$ ja alaraja ajankäytölle on samoin $\Omega(n)$,
joten voimme sanoa, että algoritmi vie aikaa $\Theta(n)$ sekä pahimmassa
että parhaassa tapauksessa.

Tarkastellaan sitten seuraavaa algoritmia, joka selvittää,
onko taulukossa lukua $x$:

\begin{code}
ok = false;
for (int i = 0; i < n; i++) {
    if (taulu[i] == x) {
        ok = true;
        break;
    }
}
\end{code}

Tässä algoritmin pahin ja paraus tapaus eroavat.
Ajankäytön yläraja on $O(n)$, koska algoritmi joutuu käymään
läpi kaikki taulukon alkiot silloin, kun luku $x$
ei esiinny taulukossa.
Toisaalta ajankäytön alaraja on $\Omega(1)$,
koska jos luku $x$ on taulukon ensimmäinen alkio,
algoritmi pysähtyy heti taulukon alussa.
Voimme myös sanoa, että algoritmi suorittaa pahimmassa
tapauksessa $\Theta(n)$ askelta ja parhaassa tapauksessa
$\Theta(1)$ askelta.

Tärkeä huomio on, että $O$-merkinnän antama yläraja voi olla mikä tahansa yläraja.
On siis oikein sanoa esimerkiksi, että taulukon lukujen summan
laskeva algoritmi vie aikaa $O(n^2)$, vaikka on olemassa parempi yläraja $O(n)$.
Miksi sitten käytämme $O$-merkintää, vaikka voisimme usein myös ilmaista tarkan
ajankäytön $\Theta$-merkinnällä?
Tämä on vakiintunut ja käytännössä toimiva tapa.
Olisi hyvin harhaanjohtavaa antaa algoritmille yläraja $O(n^2)$,
jos näemme suoraan, että aikaa kuluu vain $O(n)$.

Asiaa voi ajatella niin, että $O$-merkintää käytetään algoritmin
markkinoinnissa. Jos annamme liian suuren ylärajan, algoritmista
tulee väärä käsitys yleisölle.
Vertauksena jos myymme urheiluautoa, jonka huippunopeus on 250 km/h,
on sinänsä paikkansa pitävä väite, että autolla pystyy ajamaan 100 km/h.
Meidän ei kuitenkaan kannata antaa tällaista vähättelevää tietoa,
vaan kertoa, että autolla pystyy ajamaan 250 km/h.

\subsection{Tilavaativuus}

Merkintöjä $O$, $\Omega$ ja $\Theta$ voi käyttää
kaikenlaisissa yhteyksissä, ei vain algoritmin ajankäytön arvoinnissa.
Esimerkiksi voimme sanoa, että algoritmi suorittaa silmukkaa $O(\log n)$ kierrosta
tai että taulukossa on $O(n^2)$ lukua.

Aikavaativuuden lisäksi kiinnostava tieto algoritmista on sen
\emph{tilavaativuus}. Tämä tarkoittaa yleensä sitä, miten paljon algoritmi
käyttää muistia syötteen lisäksi.
Jos tilavaativuus on $O(1)$, algoritmi tarvitsee muistia
vain yksittäisille muuttujille syötteen lisäksi.
Jos tilavaativuus on $O(n)$, algoritmi voi varata esimerkiksi aputaulukon,
jonka koko vastaa syötteen kokoa.

Tarkastellaan esimerkkinä tehtävää, jossa meille annetaan taulukko,
joka sisältää luvut $1,2,\dots,n$ yhtä lukuun ottamatta,
ja tehtävämme on selvittää puuttuva luku.
Yksi tapa ratkaista tehtävä $O(n)$-ajassa on luoda aputaulukko,
joka pitää kirjaa nähdyistä luvuista.
Tällaisen ratkaisun tilavaativuus on $O(n)$,
koska aputaulukko vie $O(n)$ muistia.

\begin{code}
int[] apu = new int[n+1];
for (int i = 0; i < n-1; i++) {
    apu[taulu[i]] = 1;
}
for (int i = 1; i <= n; i++) {
    if (apu[i] == 0) puuttuva = i;
}
\end{code}

Tehtävään on kuitenkin olemassa myös toinen algoritmi,
jossa aikavaativuus on edelleen $O(n)$ mutta tilavaativuus on vain $O(1)$.
Tällainen algoritmi laskee ensin lukujen $1,2,\dots,n$ summan
ja vähentää sitten taulukossa esiintyvät luvut siitä.
Jäljelle jäävä luku on puuttuva luku.

\begin{code}
int summa = 0;
for (int i = 1; i <= n; i++) {
    summa += i;
}
for (int i = 0; i < n-1; i++) {
    summa -= taulu[i];
}
puuttuva = summa;
\end{code}

Käytännössä tilavaativuus on yleensä sivuroolissa algoritmeissa,
koska jos algoritmi vie vain vähän aikaa, se ei \emph{ehdi} käyttää kovin paljon muistia.
Erityisesti tilavaativuus ei voi olla suurempi kuin aikavaativuus.
Niinpä meidän riittää keskittyä suunnittelemaan algoritmeja,
jotka toimivat nopeasti, ja vertailla algoritmien aikavaativuuksia.

\subsection{Rajojen todistaminen}

Jos haluamme todistaa täsmällisesti, että jokin raja pätee,
meidän täytyy löytää vakiot $c$ ja $n_0$, jotka osoittavat asian.
Jos taas haluamme todistaa, että raja ei päde,
meidän täytyy näyttää, että mikään vakioiden $c$ ja $n_0$ valinta ei ole kelvollinen.

Jos haluamme todistaa rajan pätemisen,
tämä onnistuu yleensä helposti valitsemalla vakio $c$
tarpeeksi suureksi ja arvioimalla summan osia ylöspäin tarvittaessa.
Esimerkiksi jos haluamme todistaa, että $3n+5 = O(n)$, meidän tulee löytää
vakiot $c$ ja $n_0$, joille pätee, että $3n+5 \le cn$ aina kun $n>n_0$.
Tässä tapauksessa voimme valita esimerkiksi $c=8$ ja $n_0=1$,
jolloin voimme arvioida $3n+5 \le 3n+5n=8n$, kun $n \ge 1$.

Jos haluamme todistaa, että raja ei päde, tilanne on hankalampi,
koska meidän täytyy näyttää, että ei ole olemassa \emph{mitään} kelvollista
tapaa valita vakiot $c$ ja $n_0$.
Tässä auttaa tyypillisesti vastaoletuksen tekeminen: oletamme,
että raja pätee ja voimme valita vakiot,
ja näytämme sitten, että tämä oletus johtaa ristiriitaan.

Todistetaan esimerkkinä, että $n^2 \neq O(n)$.
Jos pätisi $n^2=O(n)$, niin olisi olemassa vakiot $c$ ja $n_0$,
joille $n^2 \le cn$ aina kun $n \ge n_0$.
Voimme kuitenkin osoittaa, että tämä aiheuttaa ristiriidan.
Jos $n^2 \le cn$, niin voimme jakaa epäyhtälön molemmat puolet $n$:llä
ja saamme $n \le c$.
Tämä tarkoittaa, että $n$ on aina enintään yhtä suuri kuin vakio $c$.
Tämä ei ole kuitenkaan mahdollista, koska $n$ voi olla miten
suuri tahansa, joten ei voi päteä $n^2 = O(n)$.

Tällaiselle määritelmistä lähtevälle todistamiselle ei ole kuitenkaan
käy\-tännössä tarvetta algoritmien analysoinnissa,
vaan voimme huoletta päätellä algoritmin aikavaativuuden
katsomalla, millaisia silmukoita siinä on, kuten olemme tehneet tämän luvun alkuosassa.