\chapter{Tehokkuus}

\section{Aikavaativuus}

Voimme arvioida algoritmin tehokkuutta laskemalla,
montako kertaa siinä olevia komentoja suoritetaan.
Tavoitteena on arvioida tehokkuutta suhteessa
syötteen kokoon $n$.
Esimerkiksi jos syötteenä on taulukko,
$n$ on taulukon koko,
ja jos syötteenä on merkkijono,
$n$ on merkkijonon pituus.

Tarkastellaan esimerkkinä seuraavaa algoritmia,
joka laskee, montako kertaa luku $x$ esiintyy
$n$-kokoisessa taulukossa.

\begin{code}[numbers=left]
int maara = 0;
for (int i = 0; i < n; i++) {
    if (luvut[i] == x) {
        maara++;
    }
}
\end{code}

Tässä algoritmissa oleelliset komennot ovat riveillä
1, 3 ja 4.
Rivin 1 komento suoritetaan vain kerran algoritmin alussa.
Rivin 3 komento suoritetaan $n$ kertaa jokaisella silmukan
kierroksella.
Rivin 4 komento taas suoritetaan $0 \dots n$
kertaa riippuen siitä, kuinka usein
luku $x$ esiintyy taulukossa.
Algoritmissa suoritetaan siis vähintään $n+1$ ja enintään $2n+1$
komentoa.

Näin tarkka analyysi ei ole kuitenkaan yleensä tarpeen,
vaan meille riittää usein määrittää karkea ajankäytön yläraja.
Sanomme, että algoritmi toimii ajassa $O(f(n))$ eli sen
\emph{aikavaativuus} on $O(f(n))$, jos se suorittaa
enintään $c f(n)$ komentoa aina silloin kun $n \ge n_0$,
missä $c$ ja $n_0$ ovat vakioita.
Esimerkiksi yllä oleva algoritmi toimii ajassa $O(n)$,
koska se suorittaa selkeästi enintään $3n$ komentoa
kaikilla $n$:n arvoilla.

Aikavaativuden mukavana puolena on, että yleensä voimme
määrittää aikavaativuuden hyvin helposti algoritmin
rakenteesta. Tutustumme seuraavaksi laskusääntöihin,
joiden avulla tämä on mahdollista.

\subsection{Laskusääntöjä}

Jos algoritmissa ei ole silmukoita vaan vain
yksittäisiä komentoja, sen aikavaativuus on $O(1)$.
Näin on esimerkiksi seuraavassa algoritmissa.

\begin{code}
c = a+b;
b = a;
if (a > b) a++;
\end{code}

Merkitsemme \texttt{...} koodia,
jonka aikavaativuus on $O(1)$.
Jos algoritmissa on yksi silmukka,
joka suorittaa $n$ askelta,
sen aikavaativuus on $O(n)$:

\begin{code}
for (int i = 0; i < n; i++) {
    ...
}
\end{code}

Jos tällaisia silmukoita on kaksi sisäkkäin,
aikavaativuus on $O(n^2)$:

\begin{code}
for (int i = 0; i < n; i++) {
    for (int j = 0; j < n; j++) {
        ...
    }
}
\end{code}

Yleisemmin jos algoritmissa on vastaavalla tavalla
$k$ sisäkkäistä silmukkaa,
sen aikavaativuus on $O(n^k)$.

Huomaa, että vakiokertoimet ja matalammat termit eivät vaikuta aikavaativuuteen.
Esimerkiksi seuraavia koodeja suoritetaan $2n$ ja $n-1$ kertaa,
mutta kummankin koodin aikavaativuus on $O(n)$.

\begin{code}
for (int i = 0; i < 2*n; i++) {
    ...
}
\end{code}

\begin{code}
for (int i = 0; i < n-1; i++) {
    ...
}
\end{code}

Jos algoritmissa on peräkkäisiä osuuksia, kokonaisaikavaativuus on suurin
yksittäinen aikavaativuus. Esimerkiksi seuraavan algoritmin aikavaativuus on $O(n^2)$,
koska sen osuudet ovat $O(n)$, $O(n^2)$ ja $O(n)$.

\begin{code}
for (int i = 0; i < n; i++) {
    ...
}
for (int i = 0; i < n; i++) {
    for (int j = 0; j < n; j++) {
        ...
    }
}
for (int i = 0; i < n; i++) {
    ...
}
\end{code}

Joskus aikavaativuus riippuu useammasta tekijästä,
jolloin kaavassa on monta muuttujaa.
Esimerkiksi seuraavan koodin aikavaativuus on $O(nm)$:

\begin{code}
for (int i = 0; i < n; i++) {
    for (int j = 0; j < m; j++) {
        ...
    }
}
\end{code}

\subsection{Yleisiä aikavaativuuksia}

Tietyt aikavaativuudet esiintyvät usein algoritmien analyysissa.
Seuraavaksi käymme läpi joukon tällaisia aikavaativuuksia.

\subsubsection{$O(1)$ (vakioaikainen)}

Vakioaikainen algoritmi suorittaa vain kiinteän määrän komentoja.
Tyypillinen vakioaikainen algoritmi on kaava, joka laskee
suoraan vastauksen. Esimerkiksi seuraava algoritmi laskee
summan $1+2+\dots+n$ vakioajassa:

\begin{code}
summa = n*(n+1)/2;
\end{code}

\subsubsection{$O(\log n)$ (logaritminen)}

Logaritminen algoritmi puolittaa usein syötteen koon
joka askeleella. Tyypillinen esimerkki logaritmisesta algoritmista
on binäärihaku, joka etsii alkiota järjestetystä taulukosta.

\begin{code}
int a = 0;
int b = n-1;
while (a <= b) {
    int c = (a+b)/2;
    if (taulu[c] == x) break;
    if (taulu[c] < x) a = c+1;
    else b = c-1;
}
\end{code}

\subsubsection{$O(n)$ (lineaarinen)}

Lineaarinen algoritmi voi käydä läpi syötteen kiinteän määrän kertoja.
Esimerkiksi seuraava algoritmi laskee taulukon lukujen summan $O(n)$-ajassa.

\begin{code}
int summa = 0;
for (int i = 0; i < n; i++) {
    summa += taulu[i];
}
\end{code}

\subsubsection{$O(n \log n)$ (järjestäminen)}

Aikavaativuus $O(n \log n)$ viittaa usein siihen,
että algoritmi järjestää taulukon,
koska tehokkaat algoritmit taulukon järjestämiseen
vievät aikaa $O(n \log n)$.
Esimerkiksi seuraava algoritmi laskee ajassa
$O(n \log n)$, montako eri alkiota taulukko sisältää.

\begin{code}
Arrays.sort(taulu);
int maara = 1;
for (int i = 1; i < n; i++) {
    if (taulu[i] != taulu[i-1]) maara++;
}
\end{code}

\subsubsection{$O(n^2)$ (neliöllinen)}

Neliöllinen algoritmi voi käydä läpi kaikki tavat valita
kaksi alkiota taulukosta.
Esimerkiksi seuraava $O(n^2)$-algoritmi tutkii, onko taulukossa
kahta lukua, joiden summa on $x$.

\begin{code}
boolean ok = false;
for (int i = 0; i < n; i++) {
    for (int j = i+1; j < n; j++) {
        if (taulu[i]+taulu[j] == x) ok = true;
    }
}
\end{code}

\subsubsection{$O(n^3)$ (kuutiollinen)}

Kuutiollinen algoritmi voi käydä läpi kaikki tavat valita
kolme alkiota taulukosta.
Esimerkiksi seuraava $O(n^3)$-algoritmi tutkii, onko taulukossa
kolmea lukua, joiden summa on $x$.

\begin{code}
boolean ok = false;
for (int i = 0; i < n; i++) {
    for (int j = i+1; j < n; j++) {
        for (int k = j+1; k < n; k++) {
            if (taulu[i]+taulu[j]+taulu[k] == x) ok = true;
        }
    }
}
\end{code}

\subsubsection{$O(2^n)$ (osajoukot)}

Aikavaativuus $O(2^n)$ viittaa usein siihen,
että algoritmi käy läpi syötteen alkioiden osajoukot.
Esimerkiksi alkioiden $\{1,2,3\}$ osajoukot ovat
$\emptyset$, $\{1\}$, $\{2\}$, $\{3\}$, $\{1,2\}$, $\{1,3\}$, $\{2,3\}$ ja $\{1,2,3\}$

\subsubsection{$O(n!)$ (permutaatiot)}

Aikavaativuus $O(n!)$ viittaa usein siihen,
että algoritmi käy läpi syötteen alkioiden permutaatiot.
Esimerkiksi alkioiden $\{1,2,3\}$ permutaatiot ovat
$(1,2,3)$, $(1,3,2)$, $(2,1,3)$, $(2,3,1)$, $(3,1,2)$ ja $(3,2,1)$.

\subsection{Tehokkuuden arviointi}

Mitä hyötyä on määrittää algoritmin aikavaativuus?
Hyötynä on, että se kertoo meille pika-arvion siitä,
kuinka \emph{hyvä} algoritmi on eli miten suuria syötteitä
sillä voi käsitellä tehokkaasti.
Kun meille kertyy kokemusta algoritmien suunnittelusta,
meille alkaa muodostua selkeä kuva,
mitä eri aikavaativuudet tarkoittavat käytännössä.

Aikavaativuutta voi ajatella samalla tavalla kuin vaikkapa
hotellin tähti\-luokitusta: se kertoo tiiviissä tilassa,
mistä asiassa on kysymys, eikä meidän tarvitse ottaa selvää yksityiskohdista.
Jos meille tarjoitaan majoitusta neljän tähden hotellissa,
saamme heti jonkin käsityksen huoneen tasosta,
vaikka emme saisi tarkkaa kuvausta huoneen varustelusta.
Vastaavasti jos kuulemme, että jonkin algoritmin aikavaativuus on $O(n \log n)$,
voimme heti arvioida karkeasti, miten suuria syötteitä voimme käsitellä,
vaikka emme saisi tarkkaa kuvausta algoritmin toiminnasta.

\begin{table}
\center
\begin{tabular}{rrr}
aikavaativuus & syötteen koko \\
\hline
$O(n)$ & $10^6$ & \\
$O(n \log n)$ & $10^5$ & \\
$O(n^2)$ & 2500 & \\
$O(n^3)$ & 250 & \\
$O(2^n)$ & 20 & \\
$O(n!)$ & 10 & \\
\end{tabular}
\caption{Kuinka suuren syötteen algoritmi voi käsitellä sekunnissa?}
\label{tab:algteh}
\end{table}

Yksi kiinnostava näkökulma algoritmin tehokkuuteen on,
miten suuren syötteen algoritmi voi käsitellä sekunnissa.
Taulukossa \ref{tab:algteh} on joitakin hyödyl\-lisiä arvioita
olettaen, että algoritmi suoritetaan tavallisella modernilla tietokoneella.
Esimerkiksi jos meillä on $O(n^2)$-algoritmi, voimme käsitellä sillä
tehokkaasti taulukon, jossa on muutamia tuhansia alkioita.
Jos tavoitteemme on käsitellä tehokkaasti suuria syötteitä,
meidän tulisi pyrkiä löytämään $O(n)$- tai $O(n \log n)$-aikainen
algoritmi.

Huomaa kuitenkin, että nämä luvut ovat vain arvioita ja algoritmin
todelliseen ajankäyttöön vaikuttavat monet asiat.
Saman algoritmin hyvä toteutus saattaa olla
kymmenen kertaa nopeampi kuin huono toteutus,
vaikka aikavaativuudet olisivat samat.
Tässä kirjassa analysoimme algoritmeja sekä aikavaativuuksien
avulla että mittaamalla todellisia suoritusaikoja.

\section{Esimerkki}

Seuraavaksi käymme läpi esimerkin, jossa vertailemme kahta
erilaista algoritmia samaan tehtävään.
Ensimmäinen algoritmi on suoraviivainen raa'an voiman
algoritmi, joka toimii ajassa $O(n^2)$.
Toinen algoritmi taas on tehokas algoritmi,
joka toimii ajassa $O(n)$.

Tehtävämme on seuraava: Annettuna on bittijono, jossa on $n$ bittiä,
ja tehtävämme on laskea, monellako tavalla voimme valita kaksi kohtaa
niin, että vasen bitti on 0 ja oikea bitti on 1.
Esimerkiksi bittijonossa 01001 tapoja on neljä:
\underline{01}001, \underline{0}100\underline{1},
01\underline{0}0\underline{1} ja 010\underline{01}.

\subsubsection{$O(n^2)$-ratkaisu}

Suoraviivainen tapa ratkaista tehtävä on käydä läpi kaikki
mahdolliset tavat valita vasen ja oikea kohta ja laskea,
monessako tavassa vasen bitti on 0 ja oikea bitti on 1.
Seuraava metodi \texttt{laskeParit} toteuttaa tällaisen algoritmin.
Sille annetaan parametrina taulukko \texttt{bitit},
joka sisältää $n$ bittiä, ja metodi palauttaa vastauksena
tapojen määrän.

\begin{code}
public long laskeParit(int[] bitit) {
    int n = bitit.length;
    long tulos = 0;
    for (int i = 0; i < n; i++) {
        for (int j = i+1; j < n; j++) {
            if (bitit[i] == 0 && bitit[j] == 1) tulos++;
        }
    }
    return tulos;
}
\end{code}

Algoritmin aikavaativuus on $O(n^2)$, koska siinä on kaksi
sisäkkäistä silmukkaa, jotka käyvät läpi syötteen.

\subsubsection{$O(n)$-ratkaisu}

Kuinka voisimme ratkaista tehtävän tehokkaammin?
Meidän tulisi keksiä tapa, jolla saisimme
pois toisen silmukan koodista.

Tässä auttaa lähestyä ongelmaa hieman toisesta
näkökulmasta: kun olemme tietyssä kohdassa bittijonoa,
monellako tavalla voimme muodostaa parin,
jonka oikea bitti on nykyisessä kohdassamme?
Jos olemme bitin 0 kohdalla, pareja ei ole yhtään,
mutta jos bittinä on 1, voimme valita minkä tahansa
vasemmalla puolella olevan bitin 0 pariin.

Tämän havainnon ansiosta meidän riittää käydä läpi
bittijono kerran vasemmalta oikealle ja pitää kirjaa,
montako bittiä 0 olemme nähneet.
Sitten jokaisen bitin 1 kohdalla kasvatamme
vastausta tällä bittien 0 määrällä.
Seuraava koodi toteuttaa algoritmin:

\begin{code}
public long laskeParit(int[] bitit) {
    int n = bitit.length;
    long tulos = 0;
    int nollat = 0;
    for (int i = 0; i < n; i++) {
        if (bitit[i] == 0) nollat++;
        if (bitit[i] == 1) tulos += nollat;
    }
    return tulos;
}
\end{code}

Algoritmissa on vain yksi silmukka, joka käy syötteen läpi,
joten sen aikavaativuus on $O(n)$.

\subsubsection{Algoritmien vertailua}

Meillä on siis kaksi algoritmia, joiden aikavaativuudet ovat
$O(n^2)$ ja $O(n)$, mutta mitä tämä tarkoittaa käytännössä?
Tämän selvittämiseksi teimme testin,
jossa mittasimme algoritmien suoritusaikoja
satunnaisilla syötteillä eri $n$:n arvoilla.

Taulukko \ref{tab:algver} näyttää testin tulokset.
Pienillä $n$:n arvoilla molemmat algoritmit toimivat
hyvin tehokkaasti, mutta suuremmilla syötteillä on
nähtävissä huomattavia eroja.
Raakaan voimaan perustuva $O(n^2)$-algoritmi
alkaa hidastua selvästi testistä $n=10000$ alkaen,
ja testissä $n=1000000$ sillä kuluu jo lähes kolme minuuttia aikaa.
Tehokas $O(n)$-algoritmi taas selvittää suuretkin testit
salamannopeasti.

\begin{table}
\center
\begin{tabular}{rrr}
syötteen koko $n$ & $O(n^2)$-algoritmi & $O(n)$-algoritmi \\
\hline
$10$ & 0.00 s & 0.00 s\\
$100$ & 0.00 s & 0.00 s\\
$1000$ & 0.00 s & 0.00 s\\
$10000$ & 0.14 s & 0.00 s \\
$100000$ & 1.66 s & 0.00 s \\
$1000000$ & 172.52 s & 0.01 s \\
\end{tabular}
\caption{Algoritmien suoritusaikojen vertailu.}
\label{tab:algver}
\end{table}

Tämän kurssin keskeinen tavoitteemme on luoda algoritmeja,
jotka toimivat tehokkaasti myös silloin, kun niille annetaan suuria syötteitä.
Tämä tarkoittaa käytännössä sitä, että algoritmin aikavaativuuden tulisi
olla $O(n)$ tai $O(n \log n)$.
Jos algoritmin aikavaativuus on esimerkiksi $O(n^2)$,
se on auttamatta liian hidas suurien syötteiden käsittelyyn.

\section{Lisää algoritmien analysoinnista}

Aikavaativuuksissa käyttämämme $O$-merkintä on yksi monista merkinnöistä,
joiden avulla voimme arvioida funktioiden kasvunopeutta.
Tutustumme seuraavaksi tarkemmin näihin merkintöihin.

\subsection{Merkinnät $O$, $\Omega$ ja $\Theta$}

Algoritmien analysoinnissa tärkeimmät merkinnät ovat:

\begin{itemize}
\item \emph{Yläraja}: Funktio $g(n)$ on luokkaa $O(f(n))$, jos on olemassa vakiot $c$ ja $n_0$
niin, että $g(n) \le c f(n)$ aina kun $n \ge n_0$.
\item \emph{Alaraja}: Funktio $g(n)$ on luokkaa $\Omega(f(n))$, jos on olemassa vakiot $c$ ja $n_0$
niin, että $g(n) \ge c f(n)$ aina kun $n \ge n_0$.
\item \emph{Tarkka arvio}: Funktio $g(n)$ on luokkaa $\Theta(f(n))$, jos se on sekä luokkaa $O(f(n))$
että luokkaa $\Omega(f(n))$.
\end{itemize}

Vakion $c$ tarkoituksena on, että saamme arvion kasvunopeuden suuruusluokalle välittämättä
vakiokertoimista. Vakion $n_0$ tarkoituksena on, että keskitymme tarkastelemaan
kasvunopeutta suurilla $n$:n arvoilla.

Kun sanomme, että algoritmi toimii ajassa $O(f(n))$, tarkoitamme, että se suorittaa
\emph{pahimmassa tapauksessa} $O(f(n))$ komentoa.
Tämä on yleensä hyvä tapa ilmoittaa algoritmin tehokkuus,
koska silloin annamme takuun siitä, että algoritmin ajankäytöllä on tietty yläraja,
vaikka syöte olisi valittu mahdollisimman hankalaksi.

Tarkastellaan esimerkkinä seuraavaa algoritmia, joka laskee
taulukon lukujen summan:

\begin{code}
int summa = 0;
for (int i = 0; i < n; i++) {
    summa += taulu[i];
}
\end{code}

Tämä algoritmi toimii samalla tavalla riippumatta taulukon sisällöstä,
koska se käy aina läpi koko taulukon.
Niinpä yläraja ajankäytölle on $O(n)$ ja alaraja ajankäytölle on samoin $\Omega(n)$,
joten voimme sanoa, että algoritmi vie aikaa $\Theta(n)$ sekä pahimmassa
että parhaassa tapauksessa.

Tarkastellaan sitten seuraavaa algoritmia, joka selvittää,
onko taulukossa lukua $x$:

\begin{code}
ok = false;
for (int i = 0; i < n; i++) {
    if (taulu[i] == x) {
        ok = true;
        break;
    }
}
\end{code}

Tässä algoritmin pahin ja paraus tapaus eroavat.
Ajankäytön yläraja on $O(n)$, koska algoritmi joutuu käymään
läpi kaikki taulukon alkiot silloin, kun luku $x$
ei esiinny taulukossa.
Toisaalta ajankäytön alaraja on $\Omega(1)$,
koska jos luku $x$ on taulukon ensimmäinen alkio,
algoritmi pysähtyy heti taulukon alussa.
Voimme myös sanoa, että algoritmi suorittaa pahimmassa
tapauksessa $\Theta(n)$ komentoa ja parhaassa tapauksessa
$\Theta(1)$ komentoa.

Huomaa, että $O$-merkinnän antama yläraja voi olla mikä tahansa yläraja.
On siis oikein sanoa esimerkiksi, että taulukon lukujen summan
laskeva algoritmi vie aikaa $O(n^2)$, vaikka on olemassa parempi yläraja $O(n)$.
Miksi sitten käytämme $O$-merkintää, vaikka voisimme usein myös ilmaista tarkan
ajankäytön $\Theta$-merkinnällä?
Tämä on vakiintunut ja käytännössä toimiva tapa.
Olisi hyvin harhaanjohtavaa antaa yläraja $O(n^2)$,
jos näemme suoraan, että aikaa kuluu vain $O(n)$.

Asiaa voi ajatella niin, että $O$-merkintää käytetään algoritmin
markkinoinnissa. Jos annamme liian suuren ylärajan, algoritmista
tulee väärä käsitys.
Vertauksena jos myymme urheiluautoa, jonka huippunopeus on 250 km/h,
on sinänsä paikkansa pitävä väite, että autolla pystyy ajamaan 100 km/h.
Meidän ei kuitenkaan kannata ilmoittaa tällaista rajaa,
vaan kertoa, että autolla pystyy ajamaan 250 km/h.

\subsection{Tilavaativuus}

Merkintöjä $O$, $\Omega$ ja $\Theta$ voi käyttää
kaikenlaisissa yhteyksissä, ei vain algoritmin ajankäytön arvoinnissa.
Esimerkiksi voimme sanoa, että algoritmi suorittaa silmukkaa $O(\log n)$ kierrosta
tai että taulukossa on $O(n^2)$ alkiota.

Aikavaativuuden lisäksi kiinnostava tieto algoritmista voi olla sen
\emph{tilavaativuus}. Tämä tarkoittaa yleensä sitä, miten paljon algoritmi
käyttää muistia syötteen lisäksi.
Jos tilavaativuus on $O(1)$, algoritmi tarvitsee muistia
vain yksittäisille muuttujille syötteen lisäksi.
Jos tilavaativuus on $O(n)$, algoritmi voi varata esimerkiksi aputaulukon,
jonka koko vastaa syötteen kokoa.

Tarkastellaan esimerkkinä tehtävää, jossa meille annetaan taulukko,
joka sisältää luvut $1,2,\dots,n$ yhtä lukuun ottamatta,
ja tehtävämme on selvittää puuttuva luku.
Yksi tapa ratkaista tehtävä $O(n)$-ajassa on luoda aputaulukko,
joka pitää kirjaa nähdyistä luvuista.
Tällaisen ratkaisun tilavaativuus on $O(n)$.

\begin{code}
int[] apu = new int[n+1];
for (int i = 0; i < n-1; i++) {
    apu[taulu[i]] = 1;
}
for (int i = 1; i <= n; i++) {
    if (apu[i] == 0) puuttuva = i;
}
\end{code}

Tehtävään on kuitenkin olemassa myös toinen algoritmi,
jossa aikavaativuus on edelleen $O(n)$, mutta tilavaativuus on vain $O(1)$.
Tämä on mahdollista laskemalla ensin lukujen $1,2,\dots,n$ summa
ja vähentämällä sitten taulukossa esiintyvät luvut siitä.
Jäljelle jäävä luku on puuttuva luku.

\begin{code}
int summa = 0;
for (int i = 1; i <= n; i++) {
    summa += i;
}
for (int i = 0; i < n-1; i++) {
    summa -= taulu[i];
}
puuttuva = summa;
\end{code}

Käytännössä tilavaativuus on yleensä sivuroolissa algoritmeissa,
koska jos meillä on tehokas algoritmi, se ei \emph{ehdi} käyttää kovin paljon muistia.
Erityisesti tilavaativuus ei voi olla suurempi kuin aikavaativuus.

\subsection{Rajojen todistaminen}

Jos haluamme todistaa täsmällisesti, että jokin raja pätee,
meidän täytyy löytää vakiot $c$ ja $n_0$, jotka osoittavat asian.
Jos taas haluamme todistaa, että raja ei päde,
meidän täytyy näyttää, että mikään vakioiden $c$ ja $n_0$ valinta ei ole kelvollinen.

Jos haluamme todistaa rajan pätemisen,
tämä onnistuu yleensä helposti valitsemalla vakio $c$
tarpeeksi suureksi ja arvioimalla summan osia ylöspäin tarvittaessa.
Esimerkiksi jos haluamme todistaa, että $3n+5 = O(n)$, meidän tulee löytää
vakiot $c$ ja $n_0$, joille pätee että $3n+5 \le cn$ aina kun $n>n_0$.
Tässä tapauksessa voimme valita esimerkiksi $c=8$ ja $n_0=1$,
jolloin voimme arvioida $3n+5 \le 3n+5n=8n$, kun $n \ge 1$.

Jos haluamme todistaa, että raja ei päde, tilanne on hankalampi,
koska meidän täytyy näyttää, että ei ole olemassa \emph{mitään} kelvollista
valintaa vakioille $c$ ja $n_0$.
Tässä auttaa usein vastaoletuksen tekeminen: oletamme,
että raja pätee ja voimme valita vakiot,
ja näytämme sitten, että tämä johtaa kuitenkin ristiriitaan.

Todistetaan esimerkkinä, että $n^2 \neq O(n)$.
Jos pätisi $n^2=O(n)$, niin olisi olemassa vakiot $c$ ja $n_0$,
joille $n^2 \le cn$ aina kun $n \ge n_0$.
Voimme kuitenkin osoittaa, että tämä aiheuttaisi ristiriidan.
Jos $n^2 \le cn$, niin voimme jakaa molemmat puolet $n$:llä
ja saamme $n \le c$.
Tämä tarkoittaa, että $n$ on aina enintään yhtä suuri kuin vakio $c$.
Tämä ei ole kuitenkaan mahdollista, koska $n$ voi olla miten
suuri tahansa, joten ei voi päteä $n^2 = O(n)$.