\chapter{Algoritmien suunnittelu}

Kuinka voi suunnitella hyvän algoritmin?
On selvää, ettei tähän kysymykseen ole helppoa vastausta.
Yhtä hyvin voisi kysyä, kuinka voi kirjoittaa hyvän kirjan
tai säveltää hyvää musiikkia.

Tämän kurssin keskeinen tavoitteemme on saada aikaan tehokkaita algoritmeja,
jotka toimivat ajassa $O(n)$ tai $O(n \log n)$.
Kun tämä tavoite on tiedossa, voimme ottaa sen algoritmien
suunnittelun lähtökohdaksi ja kartoittaa sen avulla mahdollisia
lähestymistapoja, joita voimme käyttää.

\section{Perustekniikoita}

Millainen on algoritmi, joka vie aikaa $O(n)$ tai $O(n \log n)$?
Tämä tarkoittaa,
että kun algoritmille annetaan syötteenä $n$ alkiota,
se saa käyttää jokaisen alkion käsittelyyn
vain pienen määrän aikaa.
Niinpä algoritmissa tulisi esiintyä seuraavan kaltaisia silmukoita:

\begin{code}
for (int i = 0; i < n; i++) {
    // tee jotain nopeaa
}
\end{code}

Tässä ''jotain nopeaa'' tarkoittaa koodia, joka vie aikaa
$O(1)$ tai $O(\log n)$.
Algoritmi voi myös järjestää aineistoa,
koska tehokkaat järjestämisalgoritmit vievät aikaa $O(n \log n)$.
Kovin paljon muuta tehokas algoritmi ei sitten voikaan tehdä.
Tämä rajoittaa paljon, mitä aineksia voimme laittaa algoritmiin,
mutta voimme ajatella asiaa myös myönteisesti:
vaatimus tehokkuudesta rajaa pois suuren määrän lähestymistapoja,
eli meidän on helpompaa löytää hyvä algoritmi,
kun vaihtoehtojen määrä on pienempi.

Algoritmien suunnittelussa keskeisiä ovat \emph{havainnot}:
haluamme saada käsityksen,
mitä ominaisuuksia ratkaistavaan ongelmaan liittyy,
jotta voimme käyttää niitä algoritmissa.
Voimme tehdä havaintoja tutkimalla ongelman pieniä tapauksia
ja etsimällä riippuvuuksia ja säännöllisyyksiä.
Jos käy hyvin, huomaamme asioita, jotka pätevät kaikissa ongelman
tapauksissa, ja voimme hyödyntää niitä koko tehtävän ratkaisemisessa.

\subsection{Algoritmin tehostaminen}

Tavallinen tilanne algoritmien suunnittelussa on,
että pystymme ratkaisemaan annetun ongelman
helposti $O(n^2)$-ajassa ensimmäisellä mieleen tulevalla algoritmilla,
mutta haasteena on keksiä tehokkaampi algoritmi,
joka toimisi ajassa $O(n)$ tai $O(n \log n)$.
Kokemus on osoittanut, että tämä on hyvä tilanne:
yleensä \emph{pystymme} tehostamaan
tavalla tai toisella algoritmia,
kunhan mietimme huolellisesti asiaa.

Tarkastellaan esimerkkinä seuraavaa tehtävää:
Annettuna on taulukko, joka sisältää luvut $1,2,\dots,n$
jossakin järjestyksessä,
ja haluamme kerätä taulukon luvut järjestyksessä pienimmästä suurimpaan.
Joka kierroksella käym\-me läpi taulukon vasemmalta
oikealle ja keräämme mahdollisimman monta seuraavaa lukua.
Montako kierrosta tarvitsemme yhteensä?
Esimerkiksi taulukossa $[4,3,1,5,2]$
tarvitsemme kolme kierrosta:
ensimmäisellä kierroksella keräämme luvut $1$ ja $2$,
toisella luvun $3$ ja kolmannella luvut $4$ ja $5$.

Voimme ratkaista tehtävän suoraviivaisesti $O(n^2)$-ajassa
simuloimalla lukujen keräämistä tehtävänannon kuvaamalla tavalla:

\begin{code}
int luku = 1;
int laskuri = 0;
while (luku <= n) {
    laskuri++;
    for (int i = 0; i < n; i++) {
        if (taulu[i] == luku) luku++;
    }
}
System.out.println(laskuri);
\end{code}

Tässä muuttuja \texttt{luku} kertoo,
minkä luvun haluamme kerätä seuraavaksi,
ja muuttuja \texttt{laskuri} laskee,
montako kierrosta tarvitaan.
Kierroksia tarvitaan aina korkeintaan $n$,
koska saamme kerättyä joka kierroksella
ainakin yhden luvun,
joten algoritmi toimii ajassa $O(n^2)$.

Kuinka voisimme sitten tehostaa algoritmia niin,
että se veisi aikaa vain $O(n)$ tai $O(n \log n)$?
Yllä olevan algoritmin hitaus johtuu pohjimmiltaan siitä,
että algoritmilla menee kauan aikaa löytää,
missä kohtaa taulukossa on seuraava luku,
jonka haluamme kerätä.
Niinpä jotta voimme ratkaista tehtävän tehokkaasti,
meidän täytyy jollakin tavalla löytää seuraava kerät\-tävä luku nopeammin.
Kätevä ratkaisu tähän on luoda aputaulukko,
joka kertoo jokaisen luvun kohdan:

\begin{code}
int[] kohta = new int[n+1];
for (int i = 0; i < n; i++) {
    kohta[taulu[i]] = i;
}
\end{code}

Tämän taulukon avulla saamme selville $O(1)$-ajassa,
missä kohdassa taulukossa on seuraava kerättävä luku.
Entä mistä tiedämme, montako kierrosta tarvitsemme?
Meidän täytyy aloittaa uusi kierros aina silloin,
kun viimeksi keräämämme luku on myöhemmin taulukossa
kuin seuraava kerättävä luku.
Niinpä voimme laskea kierrosten määrän näin:

\begin{code}
int laskuri = 1;
for (int i = 2; i <= n; i++) {
    if (kohta[i-1] > kohta[i]) {
        laskuri++;
    }
}
System.out.println(laskuri);
\end{code}

Tuloksena on algoritmi, jossa on kaksi silmukkaa,
joista molemmat vievät aikaa vain $O(n)$.
Niinpä algoritmin aikavaativuus on $O(n)$,
eli olemme saavuttaneet tavoitteemme.

\subsection{Ahneet algoritmit}

Tehokkaan algoritmin saaminen aikaan vaatii usein,
että pystymme tekemään algoritmissa jotain \emph{ahneesti}.
Tämä tarkoittaa, että meidän ei tarvitse käydä läpi
kaikkia mahdollisia ratkaisuja vaan pystymme rakentamaan
ratkaisun suoraan askel askeleelta käsittelemällä
syötteen sopivassa järjestyksessä.

Tarkastellaan esimerkkinä seuraavaa tehtävää:
Meillä on $n$ kolikkoa, jonka jokaisen arvo on positiivinen kokonaisluku,
ja haluamme selvittää pienimmän summan, jota \emph{ei} voi muodostaa kolikoista.
Esimerkiksi jos kolikot ovat $[1,2,2,9]$, voimme muodostaa summat
$1$, $2$, $1+2=3$, $2+2=4$ ja $1+2+2=5$,
mutta emme voi muodostaa summaa $6$.

Tämä tehtävä vaikuttaa ensi silmäykseltä vaikealta,
koska mahdollisia tapoja summien muodostamiseen on niin paljon.
Kun meillä on $n$ kolikkoa, voimme valita $2^n$ tavalla
kolikoiden osajoukon, joista syntyy jokin summa.
On selvää, että algoritmista tulee liian hidas,
jos se käy läpi kaikki tällaiset osajoukot.
Jotta saisimme aikaan tehokkaan algoritmin,
meidän tulisi huomata ongelmasta jotain,
jonka ansiosta pystymme välttämään osajoukkojen läpikäynnin
ja löydämme ratkaisun suoremmin.

Yksi hyvä tapa lähestyä tehtävää ja saada jotain tietoa ongelman luonteesta
on lähteä ensin liikkeelle pienistä summista.
Haluamme muodostaa ensin summan $1$, ja tähän tarvitsemme välttämättä
kolikon, jonka arvo on $1$.
Sitten haluamme muodostaa summan $2$, mihin tarvitsemme joko
toisen kolikon $1$ tai kolikon $2$, ja sen jälkeen summan $3$,
joka voi muodostua kolikoista $1+1+1$, $1+2$ tai $3$.
Voisimme jatkaa eteenpäin, mutta vaihtoehtoja alkaa tulla
paljon ja meidän on vaikeaa hallita niitä.
Kuitenkin näyttää siltä, että meidän kannattaa aloittaa
summien muodostaminen pienistä kolikoista.

Seuraavaksi voimme yrittää alkaa miettiä ongelmaa yleisemmin.
Oletetaan, että meillä on joukko kolikoita,
joista voimme muodostaa kaikki summat $1,2,\dots,s$.
Voisimmeko ottaa mukaan vielä jonkin uuden kolikon arvoltaan $u$ niin,
että saamme muodostettua myös summan $s+1$?
Tämä on mahdollista tarkalleen silloin, kun $u \le s+1$,
eli uuden kolikon arvo saa olla enintään $s+1$.
Jos tämä ehto pätee, voimme ottaa kolikon mukaan ja
pystymme muodostamaan tämän jälkeen kaikki summat $1,2,\dots,s+u$.
Esimerkiksi jos meillä on kolikot $[1,1,3]$, voimme muodostaa
niistä summat $1,2,\dots,5$ ja uuden kolikon arvon tulee olla enintään $6$.
Jos uuden kolikon arvo on vaikkapa $4$, voimme ottaa sen mukaan ja
pystymme muodostamaan sen jälkeen kolikoista $[1,1,3,4]$ summat $1,2,\dots,9$.

Lisäksi jos meillä on monia vaihtoehtoja valita uusi kolikko,
ei ole väliä, missä järjestyksessä otamme ne mukaan vaan
voimme valita seuraavaksi minkä tahansa niistä.
Erityisesti voimme päättää, että valitsemme aina
seuraavaksi ahneesti \emph{pienimmän} mahdollisen kolikon.
Nyt meillä on koossa kaikki tarvittavat ainekset
tehokasta algoritmia varten.
Aloitamme tyhjästä joukosta ja lisäämme siihen kolikoita
pienimmästä suurimpaan niin kauan kuin mahdollista.
Lopuksi vastaus tehtävään on yhtä suurempi kuin kolikoiden
summa.
Seuraava koodi toteuttaa algoritmin:

\begin{code}
long summa = 0;
Arrays.sort(kolikot);
for (int i = 0; i < n; i++) {
    if (kolikot[i] <= summa+1) {
        summa += kolikot[i];
    } else {
        break;
    }
}
System.out.println(summa+1);
\end{code}

Kuten koodista näkyy, meidän ei tarvitse pitää yllä
kolikoiden joukkoa, vaan riittää säilyttää tietoa
joukossa olevien kolikoiden summasta muuttujassa \texttt{summa}.
Käymme läpi kolikot järjestyksessä pienimmästä suurimpaan
ja kasvatamme summaa, jos se on mahdollista.
Kun vastaan tulee ensimmäinen kolikko, jota emme voi ottaa mukaan,
silmukka päättyy, koska tämä tarkoittaa,
että emme voi valita enää mitään muutakaan kolikkoa.
Tuloksena on algoritmi, jonka aikavaativuus on $O(n \log n)$.

\section{Binäärihaku}

\emph{Binäärihaku} on tekniikka, joka pelastaa meidät monesta
kiipelistä algoritmien suunnittelussa.
Parhaiten tunnettu binäärihaun käyttötarkoitus on alkion
etsiminen järjestetystä taulukosta ajassa $O(\log n)$.
Tämä on kuitenkin vain alkusoittoa sille,
mitä binäärihaun avulla pystyy tekemään ja mikä on sen
todellinen merkitys algoritmien suunnittelussa.

\subsection{Muutoskohdan etsiminen}

Oletetaan, että meillä on funktio $f$,
jolle pätee, että $f(x)=0$, kun $x<k$,
ja $f(x)=1$, kun $x \ge k$.
Binäärihaun avulla voimme etsiä tehokkaasti,
mikä on funktion \emph{muutoskohta} $k$
eli ensimmäinen kohta, jossa funktio saa arvon $1$.
Seuraava koodi toteuttaa haun olettaen,
että $k$ on välillä $1 \dots N$:


\begin{code}
int a = 1, b = N;
while (a < b) {
    int u = (a+b)/2;
    if (f(u) == 0) a = u+1;
    if (f(u) == 1) b = u;
}
int k = a;
\end{code}

Haun joka vaiheessa tiedämme, että muutoskohta on välillä $[a,b]$.
Laskemme keskikohdan $u=(a+b)/2$ ja tutkimme funktion arvoa kohdassa $u$.
Jos $f(u)=0$, niin tiedämme, että muutoskohta on välillä $[u+1,b]$.
Jos taas $f(u)=1$, niin muutoskohdan on oltava välillä $[a,u]$.
Lopulta välillä on vain yksi alkio, jolloin olemme löytäneet muutoskohdan.
Koska välin koko puolittuu joka askeleella,
kutsumme $O(\log N)$ kertaa funktiota $f$.

Mitä hyötyä on siitä, että löydämme tehokkaasti muutoskohdan?
Tarkastellaan esimerkkinä tehtävää, jossa käytössämme on $n$ konetta
ja haluamme valmistaa niiden avulla $m$ tavaraa.
Tiedossamme on myös arvot $[x_1,x_2,\dots,x_n]$:
jokaisesta koneesta tieto, montako minuuttia vie aikaa valmistaa
yksi tavara konetta käyttäen.
Haluamme löytää aikataulun, jota seuraamalla pystymme valmistamaan
$m$ tavaraa mahdollisimman nopeasti.
Esimerkiksi jos $n=3$, $m=7$ ja koneiden nopeudet ovat $[2,3,7]$,
paras aikataulu on kuvassa \ref{fig:optkon}.
Sitä käyttäen tavaroiden muodostaminen vie aikaa $8$ minuuttia.
Käynnistämme koneen 1 neljästi hetkinä 0, 2, 4 ja 6,
koneen 2 kahdesti hetkinä 0 ja 3
ja koneen 3 kerran hetkenä 0.
Aikaa kuluu $8$ minuuttia, koska viimeisenä pysähtyy kone 1 hetkenä 8.

\begin{figure}
\center
\begin{tikzpicture}[scale=0.7]
\draw[->] (-1,1.5) -- (10,1.5);
\foreach \x in {0,...,8} \draw (\x,1.40) -- (\x,1.60);
\foreach \x in {0,...,8} \node at (\x,2) {\scriptsize $\x$};
\node at (-2,0) {kone $1$};
\draw[|-|] (0.05,0) -- (1.95,0);
\draw[|-|] (2.05,0) -- (3.95,0);
\draw[|-|] (4.05,0) -- (5.95,0);
\draw[|-|] (6.05,0) -- (7.95,0);
\node at (-2,-1.5) {kone $2$};
\draw[|-|] (0.05,-1.5) -- (2.95,-1.5);
\draw[|-|] (3.05,-1.5) -- (5.95,-1.5);
\node at (-2,-3) {kone $3$};
\draw[|-|] (0.05,-3) -- (6.95,-3);
\end{tikzpicture}
\caption{Optimaalinen tapa valmistaa 7 tavaraa vie 8 sekuntia,
kun koneiden nopeudet ovat $[2,3,7]$.}
\label{fig:optkon}
\end{figure}

Voimme pukea tehtävän binäärihaulle sopivaan muotoon niin,
että $f(x)=1$ tarkalleen silloin, kun voimme muodostaa
\emph{ainakin} $m$ tavaraa ajassa $x$.
Tällöin funktion muutoskohta $k$ vastaa tehtävän ratkaisua.
Entä miten voimme laskea funktion $f$ arvon?
Jos meillä on $u$ minuuttia aikaa ja jollakin koneella kestää $x_i$
minuuttia valmistaa yksi tavara, pystymme valmistamaan
$\lfloor u/x_i \rfloor$ tavaraa kyseistä konetta käyttäen.
Kun sitten käytössämme on kaikki koneet,
pystymme valmistamaan yhteensä
\[ s = \sum_{i=1}^n \lfloor u/x_i \rfloor \]
tavaraa. Niinpä $f(u)=0$, jos $s<m$,
ja $f(u)=1$, jos $s \ge m$. Voimme toteuttaa tämän seuraavasti:

\begin{code}
int f(int u) {
    int s = 0;
    for (int i = 1; i <= n; i++) s += u/x[i];
    return (s < m) ? 0 : 1;
}
\end{code}

Voimme kytkeä tämän metodin suoraan binäärihakuun,
jolloin tuloksena on tehokas algoritmi tehtävän ratkaisemiseen.
Meidän täytyy kuitenkin vielä valita arvo $N$,
joka on jokin yläraja kohdalle $k$.
Tässä tehtävässä helppo valinta on
\[N = x_1 \cdot m,\]
mikä vastaa ratkaisua, jossa käytämme vain ensimmäistä konetta.
On varmaa, että oikea $k$:n arvo on korkeintaan $N$,
joten binäärihaku kutsuu $O(\log N)$ kertaa metodia $\texttt{f}$.
Koska jokainen metodin kutsu vie aikaa $O(n)$,
tuloksena on algoritmi, jonka aikavaativuus on $O(n \log N)$.

Huomaa, että $\log N$ on käytännössä pieni luku riippumatta
siitä, kuinka suuri luku $N$ on.
Niinpä meidän ei tarvitse murehtia siitä,
kuinka suuria $x_1$ ja $m$ ovat,
vaan voimme luottaa siihen, että algoritmi on tehokas.

\subsection{Alitaulukot, osa 1}

Tarkastellaan sitten tehtävää, jossa annettuna on $n$
positiivista kokonaislukua sisältävä taulukko ja lisäksi kokonaisluku $x$.
Haluamme selvittää, monessako yhtenäisessä alitaulukossa
lukujen summa on $x$.
Esimerkiksi jos taulukko on $[3,2,1,1,3,1]$ ja $x=4$,
niin halutut alitaulukot ovat $[2,1,1]$, $[1,3]$ ja $[3,1]$,
eli vastaus on tässä tapauksessa $3$.

Voimme ratkaista tehtävän helposti ajassa $O(n^2)$
käymällä läpi kaikki yhtenäiset alitaulukot seuraavasti:

\begin{code}
int laskuri = 0;
for (int i = 0; i < n; i++) {
    int summa = 0;
    for (int j = i; j < n; j++) {
        summa += taulu[j];
        if (summa == x) laskuri++;
    }
}
System.out.println(laskuri);
\end{code}

Binäärihaun avulla voimme kuitenkin parantaa algoritmia niin,
että aikaa kuluu vain $O(n \log n)$.
Ideana on korvata koodin sisempi silmukka
binääri\-haulla, joka etsii tehokkaasti kohdasta $i$
alkavan alitaulukon, jonka summa on $x$, jos tällainen alitaulukko on olemassa.
Voimme käyttää binäärihakua, koska tiedämme, että taulukon kaikki
luvut ovat positiivisia, jolloin mitä enemmän lukuja laitamme alitaulukkoon,
sitä suurempi sen summa on.
Niinpä voimme etsiä ensimmäisen kohdan $j$,
jossa välin $[i,j]$ lukujen summa on ainakin $x$.
Jos summa on tasan $x$, olemme löytäneet halutun alitaulukon,
ja muuten tällaista alitaulukkoa ei ole olemassa.

Jotta voimme toteuttaa tehokkaan ratkaisun,
tarvitsemme kuitenkin vielä yhden aineksen:
meidän täytyy pystyä laskemaan algoritmin aikana tehokkaasti,
mikä on lukujen summa taulukon välillä $[a,b]$.
Tarvittava tietorakenne on \emph{summataulukko},
jossa kohdassa $k$ on taulukon
lukujen summa taulukon alusta kohtaan $k$ asti.
Seuraava koodi muodostaa taulukosta summataulukon ajassa $O(n)$:

\begin{code}
st[0] = taulu[0];
for (int i = 1; i < n; i++) {
    st[i] = st[i-1]+taulu[i];
}
\end{code}

Tämän jälkeen pystymme laskemaan $O(1)$-ajassa,
mikä on taulukon lukujen summa välillä $[a,b]$:

\begin{code}
int summa(int a, int b) {
    if (a == 0) return st[b];
    else return st[b]-st[a-1];
}
\end{code}

Nyt voimme toteuttaa binäärihaun seuraavasti:

\begin{code}
int laskuri = 0;
for (int i = 0; i < n; i++) {
    int a = i, b = n-1;
    while (a < b) {
        int u = (a+b)/2;
        if (summa(i,u) < x) a = u+1;
        else b = u;
    }
    if (summa(i,a) == x) laskuri++;
}
System.out.println(laskuri);
\end{code}

Jokaisessa kohdassa $i$ etsimme binäärihaulla väliltä $[i,n-1]$
ensimmäisen kohdan, jossa alitaulukon summa on ainakin $x$.
Sitten tarkastamme, onko summa tasan $x$,
ja jos on, kasvatamme laskuria yhdellä.
Tuloksena olevan algoritmin aikavaativuus on $O(n \log n)$,
koska jokainen binäärihaku vie summataulukon ansiosta
aikaa vain $O(\log n)$.

\section{Tasoitettu analyysi}

Tähän mennessä olemme arvioineet algoritmien tehokkuutta
lähinnä määrit\-tämällä jokaiselle silmukalle ylärajan,
montako kertaa siinä olevaa koodia suoritetaan.
Tämä onkin yleensä hyvä tapa laskea aikavaativuus,
mutta joskus ongelmaksi voi tulla, että silmukan kierrosten
määrä vaihtelee algoritmin eri vaiheissa eikä yläraja
anna oikeaa kuvaa tehokkuudesta.

Seuraavaksi tutustumme tekniikkaan nimeltä
\emph{tasoitettu analyysi}, jossa koetamme arvioida tarkemmin,
montako kertaa silmukassa olevaa koodia suoritetaan
\emph{yhteensä} algoritmin aikana.
Tämän avulla pystymme joskus huomaamaan, että algoritmi
toimii tehokkaammin kuin vaikuttaa ensin.

\subsection{Alitaulukot, osa 2}

Palaamme aluksi tehtävään, jossa meille on annettu
$n$ positiivisen kokonaisluvun taulukko ja haluamme laskea,
monenko yhtenäisen alitaulukon summa on $x$.
Olemme jo ratkaisseet tehtävän ajassa $O(n \log n)$
binäärihaun ja summataulukon avulla,
mutta nyt ratkaisemme tehtävän vielä tehokkaammin
ajassa $O(n)$ esimerkkinä tasoitetusta analyysista.

Ideana on, että meillä on kaksi muuttujaa $i$ ja $j$,
jotka osoittavat taulukkoon.
Muuttujat aloittavat taulukon alusta,
ja jokaisella vuorolla $i$ siirtyy askeleen oikealle
ja $j$ siirtyy oikealle niin kauan, kunnes välin $[i,j]$
lukujen summa on ainakin $x$.
Jos lukujen summa on tasan $x$, olemme löytäneet yhden
alitaulukon, jonka summa on $x$.
Seuraava koodi toteuttaa algoritmin:

\begin{code}
int j = -1;
int summa = 0;
int laskuri = 0;
for (int i = 0; i < n; i++) {
    while (j+1 < n && summa < x) {
        j++;
        summa += taulu[j];
    }
    if (summa == x) laskuri++;
    summa -= taulu[i];
}
System.out.println(laskuri);
\end{code}

Tästä koodista on ensin näkemältä vaikeaa määrittää algoritmin
aikavaativuutta, koska ei ole varmaa, montako kierrosta
\texttt{while}-silmukkaa suoritetaan milloinkin.
Saattaa olla, että jollakin kertaa silmukkaa ei suoriteta lainkaan
mutta toisella kertaa $O(n)$ kierrosta.
Koska silmukkaa suoritetaan aina enintään $O(n)$ kierrosta,
saamme algoritmille aikavaativuuden $O(n^2)$,
mutta antaako tämä hyvän kuvan algoritmista?

Voimme analysoida algoritmia tarkemmin kiinnittämällä huomiota
siihen, miten muuttujan $j$ arvo muuttuu algoritmissa.
Muuttujan arvo on aluksi $-1$,
se kasvaa yhdellä jokaisella \texttt{while}-silmukan kierroksella
ja silmukkaan mennään vain, jos arvo on enintään $n-1$.
Niinpä voimme päätellä, että silmukassa oleva koodi suoritetaan \emph{yhteensä}
$O(n)$ kertaa, mikä tarkoittaa sitä,
että koko algoritmin aikavaativuus on vain $O(n)$.

\subsection{Lähin pienempi edeltäjä}

Tasoitettuun analyysiin liittyy usein jokin tietorakenne,
jonka operaatioiden määrää haluamme arvioida.
Näin on myös seuraavassa tehtävässä:

Annettuna on taulukko, jossa on $n$ kokonaislukua,
ja haluamme muodostaa toisen taulukon,
jossa on jokaisen luvun \emph{lähin pienempi edeltäjä}.
Tämä tarkoittaa, että haluamme löytää jokaiselle taulukon luvulle
sitä pienemmän luvun, joka on mahdollisimman lähellä aiemmin taulukossa.
Esimerkiksi taulukon $[1,4,5,2,3,2]$
lähimmät pienemmät edeltäjät ovat $[-,1,4,1,2,1]$.
Koska luvulla $1$ ei ole pienempää edeltäjää,
sen kohdalla on merkki $-$.

Seuraavassa on $O(n^2)$-algoritmi, joka etsii
lähimmät pienemmät edeltäjät:

\begin{code}
for (int i = 0; i < n; i++) {
    for (int j = i-1; j >= 0; j--) {
        if (taulu[j] < taulu[i]) {
            edeltaja[i] = taulu[j];
            break;
        }
    }
}
\end{code}

Ratkaisemme tehtävän tehokkaasti pitämällä yllä \emph{pinoa},
jossa on kasvava lista taulukon lukuja.
Pino on tietorakenne, jossa voimme lisätä alkion pinon päälle
ja hakea tai poistaa pinon ylimmän alkion.
Voisimme toteuttaa pinon listana,
mutta Javassa on myös erikoistunut tietorakenne \texttt{Stack},
jota käytämme seuraavassa koodissa:

\begin{code}
Stack<Integer> pino = new Stack<>();
for (int i = 0; i < n; i++) {
    while (!pino.empty() && pino.peek() >= taulu[i]) {
        pino.pop();
    }
    if (!pino.empty()) {
        edeltaja[i] = pino.peek();
    }
    pino.push(taulu[i]);
}
\end{code}

Metodi \texttt{push} lisää alkion pinoon,
\texttt{peek} hakee ylimmän alkion ja \texttt{pop}
poistaa ylimmän alkion.
Ideana on, että säilytämme pinossa kasvavassa järjestyk\-sessä
ehdokkaita tulevien lukujen lähimmiksi pienimmiksi edeltäjiksi.
Jokaisessa taulukon kohdassa poistamme
pinosta lukuja, kunnes pinon ylin luku on pienempi kuin nykyinen luku
tai pino on tyhjä.
Jos pino ei ole tämän jälkeen tyhjä, sen ylin luku on nykyisen luvun
lähin pienempi edeltäjä.
Lopuksi lisäämme nykyisen luvun pinoon päälle.

Algoritmin tehokkuus riippuu siitä, montako kertaa suoritamme
\texttt{while}-silmukassa olevan koodin.
Oleellinen havainto on, että voimme poistaa pinosta
korkeintaan niin monta alkiota kuin olemme lisänneet siihen,
eli emme voi kutsua \texttt{pop}-metodia useammin kuin \texttt{push}-metodia.
Koska lisäämme pinoon $n$ alkiota, suoritamme \texttt{while}-silmukkaa
siis enintään $n$ kierrosta.
Tämän ansiosta algoritmin aikavaativuus on $O(n)$.